{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (ChatPromptTemplate,HumanMessagePromptTemplate,SystemMessagePromptTemplate)\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.schema import (SystemMessage,HumanMessage,AIMessage)\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j \n",
    "NEO4J_URL = \"neo4j://localhost:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"fireinthehole\"\n",
    "NEO4J_DATABASE = 'neo4j'\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.neo4j_graph.Neo4jGraph.html\n",
    "graph = Neo4jGraph(url=NEO4J_URL, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Load Any Text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Text Loader (.txt, .md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'raw_data/raw_summary.txt'}, page_content='= FIRST ITERATION = \\nTimothy D. Cook is the CEO of Apple Inc., who joined the company in 1998 and took over as CEO in 2009. \\nUnder his leadership, Apple became the world\\'s largest company by market capitalization and revenue, thanks to cost-saving measures such as long-term deals for flash memory that led to popular devices like the iPod Nano, iPhone, and iPad. \\nApple was founded in 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne, with the Macintosh computer, introduced in 1984, being a revolutionary graphical user interface-based system designed for the masses. \\nThe Macintosh team, led by Jef Raskin and later Steve Jobs, faced challenges in bringing the revolutionary design to life but generated cult enthusiasm with new programs like PageMaker, MORE, and Excel. \\nApple released improved versions of the Macintosh, like the Macintosh 512K, to address initial limitations. \\nApple bought NeXT in 1997, bringing Jobs back as CEO, resulting in game-changing products like the iMac, iPod, iPhone, and iPad.  \\n\\n= SECOND ITERATION = \\nTimothy D. Cook is the CEO of Apple Inc., a globally leading technology company founded in 1976 by Steve Wozniak and Steve Jobs. \\nAfter working at IBM, Cook joined Apple in 1998 and led inventory reduction measures and long-term investments in advanced technology, contributing significantly to Apple\\'s successful transformation. \\nApple revolutionized the computer industry with groundbreaking products like the Apple I, II, Lisa, Macintosh, and subsequent innovations. \\nHowever, the company faced internal issues and financial difficulties in the late 1980s and 1990s, leading to Jobs\\' departure and Wozniak\\'s withdrawal. \\nTo revive Apple, the company bought NeXT and reintroduced Jobs, who returned Apple to profitability. \\nDespite its successes, Apple faces challenges related to contractors\\' labor and environmental practices, business ethics, anti-competitive behaviors, materials sourcing, and brand loyalty. \\nCook is an advocate for political reform and engages in charitable giving. \\nThroughout its history, Apple has been recognized as a trailblazing technology company with milestones such as becoming the first U.S. company valued over $1 trillion, $2 trillion, and $3 trillion. \\nKey figures in Apple\\'s development include Wozniak, Jobs, Raskin, and Cook.\\n\\n= THIRD ITERATION = \\nTimothy D. Cook is the CEO of Apple Inc. since 2009, a globally leading technology company founded in 1976 by Steve Wozniak and Steve Jobs. \\nAfter working at IBM, Cook joined Apple in 1998 and led inventory reduction measures and long-term investments in flash memory that led to popular devices like the iPod Nano, iPhone, and iPad, contributing significantly to Apple\\'s successful transformation. \\nThe first Macintosh computer, introduced in 1984, being a revolutionary graphical user interface-based system designed for the masses.\\nHowever, the company faced internal issues and financial difficulties in the late 1980s and 1990s, leading to Jobs\\' departure and Wozniak\\'s withdrawal. \\nTo revive Apple, the company bought NeXT in 1997 and reintroduced Jobs, who returned Apple to profitability through products like iMac, iPhone, and iPad. \\nIn 2007, Apple, under Jobs\\' leadership, collaborated with Cingular (later AT&T) to develop the iPhone, a revolutionary smartphone featuring multi-touch technology, Touch ID, Face ID, and other innovative features, which has sold over 2.2 billion units as of 2018 and revolutionized the mobile phone industry. \\nApple also operates the App Store, a digital marketplace for apps on various devices, but faces accusations of monopolistic practices. \\nApple\\'s mapping service development began with the acquisition of Placebase in 2009, leading to the formation of Apple Maps. \\nThe company has explored opportunities to enter the automotive industry, including \"Project Titan,\" which involved developing electric and self-driving car technology but was later canceled in 2024. \\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('raw_data/raw_summary.txt')\n",
    "documents = loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 0}, page_content='How Good Are Low-bit Quantized LLAMA3 Models?\\nAn Empirical Study\\nWei Huang∗\\nThe University of Hong Kong\\nweih@connect.hku.hkXudong Ma∗\\nBeihang University\\nmacaronlin@buaa.edu.cn\\nHaotong Qin†\\nETH Zurich\\nhaotong.qin@pbl.ee.ethz.chXingyu Zheng\\nBeihang University\\nxingyuzheng@buaa.edu.cn\\nChengtao Lv\\nBeihang University\\nlvchengtao@buaa.edu.cnHong Chen\\nBeihang University\\n18373205@buaa.edu.cnJie Luo\\nBeihang University\\nluojie@buaa.edu.cn\\nXiaojuan Qi\\nThe University of Hong Kong\\nxjqi@eee.hku.hkXianglong Liu\\nBeihang University\\nxlliu@buaa.edu.cnMichele Magno\\nETH Zurich\\nmichele.magno@pbl.ee.ethz.ch\\nAbstract\\nMeta’s LLAMA family has become one of the most powerful open-source Large\\nLanguage Model (LLM) series. Notably, LLAMA3 models have recently been\\nreleased and achieve impressive performance across various with super-large scale\\npre-training on over 15T tokens of data. Given the wide application of low-\\nbit quantization for LLMs in resource-limited scenarios, we explore LLAMA3 ’s\\ncapabilities when quantized to low bit-width. This exploration holds the potential to\\nunveil new insights and challenges for low-bit quantization of LLAMA3 and other\\nforthcoming LLMs, especially in addressing performance degradation problems\\nthat suffer in LLM compression. Specifically, we evaluate the 10 existing post-\\ntraining quantization and LoRA-finetuning methods of LLAMA3 on 1-8 bits\\nand diverse datasets to comprehensively reveal LLAMA3 ’s low-bit quantization\\nperformance. Our experiment results indicate that LLAMA3 still suffers non-\\nnegligent degradation in these scenarios, especially in ultra-low bit-width. This\\nhighlights the significant performance gap under low bit-width that needs to be\\nbridged in future developments. We expect that this empirical study will prove\\nvaluable in advancing future models, pushing the LLMs to lower bit-width with\\nhigher accuracy for being practical. Our project is released on https://github.\\ncom/Macaronlin/LLaMA3-Quantization and quantized LLAMA3 models are\\nreleased in https://huggingface.co/LLMQ .\\n1 Introduction\\nLaunched by Meta in February 2023, the LLaMA [ 18] series2represents a breakthrough in autore-\\ngressive large language models (LLMs) using the Transformer [ 19] architecture. Right from its first\\n∗Equal Contribution.†Corresponding Author.\\n2https://llama.meta.comarXiv:2404.14047v1  [cs.LG]  22 Apr 2024'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 1}, page_content='Evaluated LLMsLLaMA3-8BLLaMA3-70B1QuantizationMethodsRTN2GPTQAWQSmoothQuantPB-LLMBiLLMQuIPDB-LLMQLoRAIR-QLoRAEvaluationDatasetsWikiText2C4PTBPIQAARC-eARC-cHellaSwag3WinograndePerplexity↓CommonSenseQA↑Post-Training QuantizationLoRA-FinetuningHumanitiesSTEMSocialOtherMMLU↑Figure 1: The overview of our empirical study\\nversion, with 13 billion parameters, it managed to outperform the much larger, closed-source GPT-3\\nmodel which boasts 175 billion parameters. On April 18, 2024, Meta introduced the LLAMA3\\nmodel, offering configurations of 8 billion and 70 billion parameters. Thanks to extensive pre-training\\non more than 15 trillion data tokens, the LLAMA3 models3have achieved state-of-the-art (SOTA)\\nperformance across a broad range of tasks, establishing the LLaMA family as among the finest\\nopen-source LLMs available for a wide variety of applications and deployment scenarios.\\nDespite their impressive performance, deploying LLAMA3 models still poses significant challenges\\ndue to resource limitations in many scenarios. Fortunately, low-bit quantization has emerged as one\\nof the most popular techniques for compressing LLMs. This technique reduces the memory and\\ncomputational requirements of LLMs during inference, enabling them to run on resource-limited\\ndevices. Addressing the performance drop that occurs after compression is a major concern for\\ncurrent LLM quantization approaches. While numerous low-bit quantization methods have been\\nproposed, their evaluations have primarily focused on the earlier and less capable LLaMA models\\n(LLAMA1 andLLAMA2 ). Thus, LLAMA3 presents a new opportunity for the LLM community\\nto assess the performance of quantization on cutting-edge LLMs and to understand the strengths\\nand limitations of existing methods. In this empirical study, our aim is to analyze the capability of\\nLLAMA3 to handle the challenges associated with degradation due to quantization.\\nOur study sets out two primary technology tracks for quantizing LLMs: Post-Training Quantization\\n(PTQ) and LoRA-FineTuning (LoRA-FT) quantization, with the aim of providing a comprehensive\\nevaluation of the LLAMA3 models’ quantization. We explore a range of cutting-edge quantization\\nmethods across technical tracks (RTN, GPTQ [ 6], AWQ [ 10], SmoothQuant [ 20], PB-LLM [ 16],\\nQuIP [ 2], DB-LLM [ 3], and BiLLM [ 9] for PTQ; QLoRA [ 5] and IR-QLoRA [ 13] for LoRA-FT),\\ncovering a wide spectrum from 1 to 8 bits and utilizing a diverse array of evaluation datasets, including\\nWikiText2, C4, PTB, CommonSenseQA datasets (PIQA, ARC-e, ARC-c, HellaSwag, Winogrande),\\nand MMLU benchmark. The overview of our study is presented as Figure 1. These evaluations\\nassess the capabilities and limits of the LLAMA3 model under current LLM quantization techniques\\nand serve as a source of inspiration for the design of future LLM quantization methods. The choice\\nto focus specifically on the LLAMA3 model is motivated by its superior performance among all\\ncurrent open-source instruction-tuned LLMs across a variety of datasets3, including 5-shot MMLU,\\n0-shot GPQA, 0-shot HumanEval, 8-shot CoT GSM-8K, and 4-shot CoT MATH. Furthermore, we\\nhave made our project and the quantized models available to the public on https://github.com/\\nMacaronlin/LLaMA3-Quantization andhttps://huggingface.co/LLMQ , respectively. This\\nnot only aids in advancing the research within the LLM quantization community but also facilitates a\\nbroader understanding and application of effective quantization techniques.\\n2 Empirical Evaluation\\n2.1 Experiment Settings\\nEvaluated LLMs. We obtain the pre-trained LLAMA3 -8B and -70B through the official repository3.\\nQuantization methods. To evaluate the performance of low-bit quantized LLAMA3 , we select\\nrepresentative LLM quantization methods with extensive influence and functionality, including 8\\n3https://github.com/meta-llama/llama3\\n2'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 2}, page_content='Table 1: Evaluation results of post-training quantization on LL AMA3-8B model\\nMethod #W #A #GPPL↓ CommonSenseQA ↑\\nWikiText2 C4 PTB PIQA ARC-e ARC-c HellaSwag Wino Avg.\\nLLAMA3 16 16 - 6.1 9.2 10.6 79.9 80.1 50.4 60.2 72.8 68.6\\nRTN4 16 128 8.5 13.4 14.5 76.6 70.1 45.0 56.8 71.0 63.9\\n3 16 128 27.9 1.1e2 95.6 62.3 32.1 22.5 29.1 54.7 40.2\\n2 16 128 1.9E3 2.5E4 1.8E4 53.1 24.8 22.1 26.9 53.1 36.0\\n8 16 - 6.2 9.5 11.2 79.7 80.8 50.4 60.1 73.4 68.9\\n4 16 - 8.7 14.0 14.9 75.0 68.2 39.4 56.0 69.0 61.5\\n3 16 - 2.2E3 5.6E2 2.0E3 56.2 31.1 20.0 27.5 53.1 35.6\\n2 16 - 2.7E6 7.4E6 3.1E6 53.1 24.7 21.9 25.6 51.1 35.3\\nGPTQ4 16 128 6.5 10.4 11.0 78.4 78.8 47.7 59.0 72.6 67.3\\n3 16 128 8.2 13.7 15.2 74.9 70.5 37.7 54.3 71.1 61.7\\n2 16 128 2.1E2 4.1E4 9.1E2 53.9 28.8 19.9 27.7 50.5 36.2\\n8 16 - 6.1 9.4 10.6 79.8 80.1 50.2 60.2 72.8 68.6\\n4 16 - 7.0 11.8 14.4 76.8 74.3 42.4 57.4 72.8 64.8\\n3 16 - 13.0 45.9 37.0 60.8 38.8 22.3 41.8 60.9 44.9\\n2 16 - 5.7E4 1.0E5 2.7E5 52.8 25.0 20.5 26.6 49.6 34.9\\nAWQ4 16 128 6.6 9.4 11.1 79.1 79.7 49.3 59.1 74.0 68.2\\n3 16 128 8.2 11.6 13.2 77.7 74.0 43.2 55.1 72.1 64.4\\n2 16 128 1.7E6 2.1E6 1.8E6 52.4 24.2 21.5 25.6 50.7 34.9\\n8 16 - 6.1 8.9 10.6 79.6 80.3 50.5 60.2 72.8 68.7\\n4 16 - 7.1 10.1 11.8 78.3 77.6 48.3 58.6 72.5 67.0\\n3 16 - 12.8 16.8 24.0 71.9 66.7 35.1 50.7 64.7 57.8\\n2 16 - 8.2E5 8.1E5 9.0E5 55.2 25.2 21.3 25.4 50.4 35.5\\nQuIP4 16 - 6.5 11.1 9.5 78.2 78.2 47.4 58.6 73.2 67.1\\n3 16 - 7.5 11.3 12.6 76.8 72.9 41.0 55.4 72.5 63.7\\n2 16 - 85.1 1.3E2 1.8E2 52.9 29.0 21.3 29.2 51.7 36.8\\nDB-LLM 2 16 128 13.6 19.2 23.8 68.9 59.1 28.2 42.1 60.4 51.8\\nPB-LLM2 16 128 24.7 79.2 65.6 57.0 37.8 17.2 29.8 52.5 38.8\\n1.7 16 128 41.8 2.6E2 1.2E2 52.5 31.7 17.5 27.7 50.4 36.0\\nBiLLM 1.1 16 128 28.3 2.9E2 94.7 56.1 36.0 17.7 28.9 51.0 37.9\\nSmoothQuant8 8 - 6.3 9.2 10.8 79.5 79.7 49.0 60.0 73.2 68.3\\n6 6 - 7.7 11.8 12.5 76.8 75.5 45.0 56.9 69.0 64.6\\n4 4 - 4.3E3 4.0E3 3.6E3 54.6 26.3 20.0 26.4 50.3 35.5\\nPTQ methods and 2 LoRA-FT methods. The implementations of our evaluated quantization methods\\nfollow their open-source repositories4. We also used eight NVIDIA A800 with 80GB GPU memory\\nfor quantitative evaluation.\\nEvaluation datasets. For the PTQ methods, we evaluate quantized LLAMA3 on the WikiText2 [ 12],\\nPTB [ 11], and a portion of the C4 dataset [ 14], using Perplexity (PPL) as the evaluation metric.\\nSubsequently, we further conduct experiments on five zero-shot evaluation tasks (PIQA [ 1], Wino-\\ngrande [ 15], ARC-e [ 4], ARC-c [ 4], and Hellaswag [ 22]) to fully validate the quantized performance\\nofLLAMA3 . For the LoRA-FT methods, we conduct the evaluation on the 5-shot MMLU bench-\\nmark [7] while also validating the aforementioned 5 zero-shot datasets for the LoRA-FT methods.\\nFor the fairness of our evaluation, we uniformly use WikiText2 as the calibration dataset for all\\nquantization methods, with a sample size of 128 and a consistent token sequence length of 2048.\\nFurthermore, for quantization methods requiring channel-wise grouping, we adopt a block size of\\n128 to balance performance and inference efficiency, which is a common practice in existing works.\\n4https://github.com/IST-DASLab/gptq ,https://github.com/mit-han-lab/llm-awq ,https:\\n//github.com/mit-han-lab/smoothquant ,https://github.com/Cornell-RelaxML/QuIP ,https:\\n//github.com/hahnyuan/PB-LLM ,https://github.com/Aaronhuang-778/BiLLM ,https://github.\\ncom/artidoro/qlora ,https://github.com/htqin/IR-QLoRA\\n3'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 3}, page_content='Table 2: Evaluation results of post-training quantization on LL AMA3-70B model\\nMethod #W #A #GPPL↓ CommonSenseQA ↑\\nWikiText2 C4 PTB PIQA ARC-e ARC-c HellaSwag Wino Avg.\\nLLAMA3 16 16 - 2.9 6.9 8.2 82.4 86.9 60.3 66.4 80.6 75.3\\nRTN4 16 128 3.6 8.9 9.1 82.3 85.2 58.4 65.6 79.8 74.3\\n3 16 128 11.8 22.0 26.3 64.2 48.9 25.1 41.1 60.5 48.0\\n2 16 128 4.6E5 4.7E5 3.8E5 53.2 23.9 22.1 25.8 53.0 35.6\\nGPTQ4 16 128 3.3 6.9 8.3 82.9 86.3 58.4 66.1 80.7 74.9\\n3 16 128 5.2 10.5 9.7 80.6 79.6 52.1 63.5 77.1 70.6\\n2 16 128 11.9 22.8 31.6 62.7 38.9 24.6 41.0 59.9 45.4\\nAWQ4 16 128 3.3 7.0 8.3 82.7 86.3 59.0 65.7 80.9 74.9\\n3 16 128 4.8 8.0 9.0 81.4 84.7 58.0 63.5 78.6 73.2\\n2 16 128 1.7E6 1.4E6 1.5E6 52.2 25.5 23.1 25.6 52.3 35.7\\nQuIP4 16 - 3.4 7.1 8.4 82.5 86.0 58.7 65.7 79.7 74.5\\n3 16 - 4.7 8.0 8.9 82.3 83.3 54.9 63.9 78.4 72.5\\n2 16 - 13.0 22.2 24.9 65.3 48.9 26.5 40.9 61.7 48.7\\nPB-LLM2 16 128 11.6 34.5 27.2 65.2 40.6 25.1 42.7 56.4 46.0\\n1.7 16 128 18.6 65.2 55.9 56.5 49.9 25.8 34.9 53.1 44.1\\nBiLLM 1.1 16 128 17.1 77.7 54.2 58.2 46.4 25.1 37.5 53.6 44.2\\nSmoothQuant8 8 - 2.9 6.9 8.2 82.2 86.9 60.2 66.3 80.7 75.3\\n6 6 - 2.9 6.9 8.2 82.4 87.0 59.9 66.1 80.6 75.2\\n4 4 - 9.6 16.9 17.7 76.9 75.8 43.5 52.9 58.9 61.6\\n2.2 Track1: Post-Training Quantization\\nAs shown in Table 1 and Table 2, we provide the performance of low-bit LLAMA3 -8B and LLAMA3 -\\n70B with 8 different PTQ methods, respectively, covering a wide bit-width spectrum from 1 to 8-bit.\\nAmong them, Round-To-Nearest (RTN) is a vanilla rounding quantization method. GPTQ [ 6] is\\ncurrently one of the most efficient and effective weight-only quantization methods, which utilizes\\nerror compensation in quantization. But under 2-3 bits, GPTQ causes severe accuracy collapse when\\nquantized LLAMA3 . AWQ [ 10] adopts an anomaly channel suppression approach to reduce the\\ndifficulty of weight quantization, and QuIP [ 2] ensures the incoherence between weights and Hessian\\nby optimizing matrix computation. Both of them can keep LLAMA3 ’s capability at 3-bit and even\\npush the 2-bit quantization to promising.\\nThe recent emergence of binarized LLM quantization methods has realized ultra-low bit-width LLM\\nweight compression. PB-LLM [ 16] employs a mixed-precision quantization strategy, retaining a\\nsmall portion of significant weight full-precision while quantizing the majority of weights to 1-bit.\\nDB-LLM [ 3] achieves efficient LLM compression through double binarization weight splitting\\nand proposes a deviation-aware distillation strategy to further enhance 2-bit LLM performance.\\nBiLLM [ 9] further pushes the LLM quantization boundary to as low as 1.1-bit through residual\\napproximation of salient weights and grouped quantization of non-salient weights. These LLM\\nquantization methods specially designed for ultra-low bit-width can achieve higher accuracy of\\nquantized LLAMA3 -8B at⩽2-bit, far outperforms methods like GPTQ, AWQ, and QuIP under\\n2-bit (even 3-bit some cases).\\nWe also perform LLAMA3 evaluation on quantized activations via SmoothQuant [ 20], which moves\\nthe quantization difficulty offline from activations to weights to smooth out activation outliers. Our\\nevaluation shows that SmoothQuant can retain the accuracy of LLAMA3 with 8- and 6-bit weights\\nand activations, but faces collapse at 4-bit.\\nMoreover, we find that the LLAMA3 -70B model shows significant robustness for various quantization\\nmethods, even in ultra-low bit-width.\\n4'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 4}, page_content='Table 3: LoRA-FT on LL AMA3-8B with Alpaca dataset\\nMethod #WMMLU ↑ CommonSenseQA ↑\\nHums. STEM Social Other Avg. PIQA ARC-e ARC-c HellaSwag Wino Avg.\\nLLAMA3 16 59.0 55.3 76.0 71.5 64.8 79.9 80.1 50.4 60.2 72.8 68.6\\nNormalFloat 4 56.8 52.9 73.6 69.4 62.5 78.6 78.5 46.2 58.8 74.3 67.3\\nQLoRA 4 50.3 49.3 65.8 64.2 56.7 76.6 74.8 45.0 59.4 67.0 64.5\\nIR-QLoRA 4 52.2 49.0 66.5 63.1 57.2 76.3 74.3 45.3 59.1 69.5 64.9\\n2.3 Track2: LoRA-FineTuning Quantization\\nExcept for the PTQ methods, we also provide the performance of 4-bit LLAMA3 -8B with 2 different\\nLoRA-FT quantization methods as shown in Table 3, including QLoRA [5] and IR-QLoRA [13].\\nOn the MMLU dataset, the most notable observation with LLAMA3 -8B under LoRA-FT quantization\\nis that low-rank finetuning on the Alpaca [ 17] dataset not only cannot compensate for the errors\\nintroduced by quantization, even making the degradation more severe. Specifically, various LoRA-FT\\nquantization methods obtain worse performance quantized LLAMA3 under 4-bit compared with their\\n4-bit counterparts without LoRA-FT. This is in stark contrast to similar phenomena on LLAMA1\\nandLLAMA2 , where, for the front one, the 4-bit low-rank finetuned quantized versions could\\neven easily surpass the original FP16 counterpart on MMLU. According to our intuitive analysis,\\nthe main reason for this phenomenon is due to LLAMA3 ’s strong performance brought by its\\nmassive pre-scale training, which means the performance loss from the original model’s quantization\\ncannot be compensated for by finetuning on a tiny set of data with low-rank parameters (which can\\nbe seen as a subset of the original model [ 8,5]). Despite the significant drop from quantization\\nthat cannot be compensated by finetuning, 4-bit LoRA-FT quantized LLAMA3 -8B significantly\\noutperforms LLAMA1 -7B and LLAMA2 -7B under various quantization methods. For instance, with\\nthe QLoRA method, 4-bit LLAMA3 -8B has an average accuracy of 57.0 (FP16: 64.8), exceeding\\n4-bit LLAMA1 -7B’s 38.4 (FP16: 34.6) by 18.6, and surpassing 4-bit LLAMA2 -7B’s 43.9 (FP16:\\n45.5) by 13.1 [ 21,13]. This implies that a new LoRA-FT quantization paradigm is needed in the era\\nof LL AMA3.\\nA similar phenomenon occurs with the CommonSenseQA benchmark. Compared to the 4-bit\\ncounterparts without LoRA-FT, the performance of the models fine-tuned using QLoRA and IR-\\nQLoRA also declined ( e.g.QLoRA 2.8% vs IR-QLoRA 2.4% on average). This further demonstrates\\nthe strength of using high-quality datasets in LLAMA3 , as the general dataset Alpaca does not\\ncontribute to the model’s performance in other tasks.\\n3 Conclusion\\nMeta’s recently released LLAMA3 models have rapidly become the most powerful LLM series, cap-\\nturing significant interest from researchers. Building on this momentum, our study aims to thoroughly\\nevaluate the performance of LLAMA3 across a variety of low-bit quantization techniques, including\\npost-training quantization and LoRA-finetuning quantization. Our goal is to assess the boundaries\\nof its capabilities in scenarios with limited resources by leveraging existing LLM quantization tech-\\nnologies. Our findings indicate that while LLAMA3 still demonstrates superior performance after\\nquantization, the performance degradation associated with quantization is significant and can even\\nlead to larger declines in many cases. This discovery highlights the potential challenges of deploying\\nLLAMA3 in resource-constrained environments and underscores the ample room for growth and\\nimprovement within the context of low-bit quantization. The empirical insights from our research are\\nexpected to be valuable for the development of future LLM quantization techniques, especially in\\nterms of narrowing the performance gap with the original models. By addressing the performance\\ndegradation caused by low-bit quantization, we anticipate that subsequent quantization paradigms\\nwill enable LLMs to achieve stronger capabilities at a lower computational cost, ultimately driving'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 4}, page_content='degradation caused by low-bit quantization, we anticipate that subsequent quantization paradigms\\nwill enable LLMs to achieve stronger capabilities at a lower computational cost, ultimately driving\\nthe progress of generative artificial intelligence, as represented by LLMs, to new heights.\\n5'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 5}, page_content='References\\n[1]Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Reasoning about phys-\\nical commonsense in natural language. In Proceedings of the AAAI conference on artificial\\nintelligence , volume 34, pages 7432–7439, 2020.\\n[2]Jerry Chee, Yaohui Cai, V olodymyr Kuleshov, and Christopher M De Sa. Quip: 2-bit quantiza-\\ntion of large language models with guarantees. Advances in Neural Information Processing\\nSystems , 36, 2024.\\n[3]Hong Chen, Chengtao Lv, Liang Ding, Haotong Qin, Xiabin Zhou, Yifu Ding, Xuebo Liu, Min\\nZhang, Jinyang Guo, Xianglong Liu, et al. Db-llm: Accurate dual-binarization for efficient llms.\\narXiv preprint arXiv:2402.11960 , 2024.\\n[4]Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick,\\nand Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning\\nchallenge. arXiv preprint arXiv:1803.05457 , 2018.\\n[5]Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. Qlora: Efficient\\nfinetuning of quantized llms. Advances in Neural Information Processing Systems , 36, 2024.\\n[6]Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-training\\nquantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 , 2022.\\n[7]Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and\\nJacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint\\narXiv:2009.03300 , 2020.\\n[8]Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu\\nChen, et al. Lora: Low-rank adaptation of large language models. In International Conference\\non Learning Representations , 2021.\\n[9]Wei Huang, Yangdong Liu, Haotong Qin, Ying Li, Shiming Zhang, Xianglong Liu, Michele\\nMagno, and Xiaojuan Qi. Billm: Pushing the limit of post-training quantization for llms. arXiv\\npreprint arXiv:2402.04291 , 2024.\\n[10] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, and Song Han. Awq:\\nActivation-aware weight quantization for llm compression and acceleration. arXiv preprint\\narXiv:2306.00978 , 2023.\\n[11] Mitch Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark\\nFerguson, Karen Katz, and Britta Schasberger. The penn treebank: Annotating predicate\\nargument structure. In Human Language Technology: Proceedings of a Workshop held at\\nPlainsboro, New Jersey, March 8-11, 1994 , 1994.\\n[12] Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture\\nmodels. arXiv preprint arXiv:1609.07843 , 2016.\\n[13] Haotong Qin, Xudong Ma, Xingyu Zheng, Xiaoyang Li, Yang Zhang, Shouda Liu, Jie Luo, Xi-\\nanglong Liu, and Michele Magno. Accurate lora-finetuning quantization of llms via information\\nretention. arXiv preprint arXiv:2402.05445 , 2024.\\n[14] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\\nYanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. The Journal of Machine Learning Research , 21(1):5485–5551, 2020.\\n[15] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An\\nadversarial winograd schema challenge at scale. Communications of the ACM , 64(9):99–106,\\n2021.\\n[16] Yuzhang Shang, Zhihang Yuan, Qiang Wu, and Zhen Dong. Pb-llm: Partially binarized large\\nlanguage models. arXiv preprint arXiv:2310.00034 , 2023.\\n6'), Document(metadata={'source': 'raw_data/2404.14047v1.pdf', 'page': 6}, page_content='[17] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\\nLiang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\\nhttps://github.com/tatsu-lab/stanford_alpaca , 2023.\\n[18] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-\\nthée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open\\nand efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\\n[19] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\\nŁukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information\\nprocessing systems , 30, 2017.\\n[20] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han.\\nSmoothquant: Accurate and efficient post-training quantization for large language models.\\nInInternational Conference on Machine Learning , pages 38087–38099. PMLR, 2023.\\n[21] Yuhui Xu, Lingxi Xie, Xiaotao Gu, Xin Chen, Heng Chang, Hengheng Zhang, Zhensu Chen,\\nXiaopeng Zhang, and Qi Tian. Qa-lora: Quantization-aware low-rank adaptation of large\\nlanguage models. arXiv preprint arXiv:2309.14717 , 2023.\\n[22] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can a\\nmachine really finish your sentence? arXiv preprint arXiv:1905.07830 , 2019.\\n7')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"raw_data/2404.14047v1.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Website Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://supertype.ai/notes/unveiling-youtube-insights-part-1/', 'title': 'Unveiling YouTube Insights - Introduction, Data Collection, Data Processing, and Database (Part 1) • Supertype', 'description': 'In this post, we will develop a website that integrates sentiment analysis techniques and a Large Language Model to provide a comprehensive understanding of YouTube comments, enabling users to extract meaningful information effortlessly.', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\nUnveiling YouTube Insights - Introduction, Data Collection, Data Processing, and Database (Part 1) • Supertype\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\nSupertype\\nProduct & Services\\n\\nPortfolio Computer Vision Custom BI Development Managed Data Analytics & Development Programmatic Report Generation\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnalytics Products & Services \\nData analytics and data engineering services\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\nBusiness Intelligence & Analytics Dashboard\\nWe design and develop custom web dashboards that integrate your data sources, presented in your custom style / branding\\n\\n\\n\\n\\n\\n\\n\\n\\nComputer Vision Research & Development\\nFrom flood detection in crop management, to facial recognition and object classification, using the latest in deep learning and AI research\\n\\n\\n\\n\\n\\n\\n\\n\\nPDF Generation as a Service\\nSupertype Summary creates a highly tailored pipeline that output bespoke PDF in seconds, not days or hours\\n\\n\\n\\n                                hot\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n\\n\\n\\nManaged Analytics Services & Development\\nBeyond analytics consulting, we can take on the full lifecycle of your data science and analytics project\\n\\n\\n\\n\\n\\n\\n\\n\\nLLM Development Service\\nBuild on OpenAI\\'s language models and open source LLM tooling such as LangChain and LlamaIndex\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nData Science by Applications \\nImplementations of data science in various industries\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\nData Science for e-Commerce\\nWeb analytics, recommender systems, media buying, and price scraping / monitoring\\n\\n\\n\\n\\n\\n\\n\\n\\nData Science for Mobile Apps & Games\\nARPU optimization, in-app analytics, user acquisition tracking and analytics\\n\\n\\n\\n\\n\\n\\n\\n\\nData Science for Financial Markets\\nBanks, financial institutions, fund managers and regulatory bodies use analytics and financial market data to gain an edge\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBespoke solution for enterprises\\n\\t\\t\\t\\t\\t\\tAdvisory & Consulting\\n\\t\\t\\t\\t\\t \\n\\n\\n\\n \\n\\n\\n\\n\\nData Science Consulting Services\\nData Science Consulting for companies that require effective, result-driven advisory on their data analytics process\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPortfolio & highlights \\nCuration of featured projects and enterprise work\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\nSupertype Sectors\\nIndonesia\\'s most comprehensive financial data provider and analytics platform\\n\\n\\n\\n\\n\\n\\n\\n\\nProject gallery\\nOur data science portfolio and past projects in a gallery view\\n\\n\\n\\n\\n\\n\\n\\n\\nSupertype Incubator\\nSupertype Incubator is a platform for data scientists and engineers to develop real-world projects sponsored and supported by Supertype\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n\\n\\n\\nEnterprise Data Science | Case Studies\\nLearn how we help companies like yours take charge of their analytics initiatives and build winning systems\\n\\n\\n\\n\\n\\n\\n\\n\\nArticles\\nField notes and observations by data scientists and engineers on the team\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticles \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tData Engineering\\n\\t\\t\\t\\t\\t \\nTechnical articles by data engineers & automation developers solving real-world problems\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\nThe Essential Guide to Docker\\n\\n\\n\\n\\n\\n\\n\\n\\nSetting up Docker Compose v2\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to Apache Airflow\\n\\n\\n\\n\\n\\n\\n\\n\\nDjango REST framework + Custom Permissions\\n\\n\\n\\n\\n\\n\\n\\n\\nDeploying Machine Learning models with VertexAI on Google Cloud Platform\\n\\n\\n\\n\\n\\n\\n\\n\\nStreaming Data Pipeline: The Full Cycle\\u200b\\n4-part series on building a real-time Streamlit analytics app powered by Kafka, Spark Streaming, Cassandra and MySQL\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n\\n\\n\\nSee More\\n\\n\\n\\n                                20+\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\tData Science\\n\\t\\t\\t\\t\\t \\nArticles and first hand observations by data scientists & analytics experts in the field\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\nData Science for App Reviews Analysis\\n\\n\\n\\n\\n\\n\\n\\n\\nAutomated Keywords Extractions from job descriptions\\n\\n\\n\\n\\n\\n\\n\\n\\nServing PyTorch Models with TorchServe\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to RFM analysis in R\\n\\n\\n\\n\\n\\n\\n\\n\\nDecision Boundaries with PCA and FAMD\\n\\n\\n\\n\\n\\n\\n\\n\\nRiver Water Level Monitoring w/ Google Data Studio\\n\\n\\n\\n\\n\\n\\n\\n\\nTwitter Sentiment Analysis End to End\\n4-part series on building and deploying a deep learning LSTM model for tweets sentiment scoring\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n\\n\\n\\nBuilding a GPT-3 app with LangChain, Django, and YouTube API\\nA detailed walkthrough of building an AI web application powered by LangChain LLM toolkit and Django\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-Cycle Data Science Consultancy\\n\\t\\t\\t\\t\\t\\tData Science & Analytics Consulting\\n\\t\\t\\t\\t\\t \\n\\n\\n\\n \\n\\n\\n\\n\\nCase Study: Central Bank of Indonesia\\nA scalable query-able API service and data archive of public opinion towards monetary policies across 100+ social media channels ft. data engineering, web automation and sentiment analysis\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Study: Adaro Water Level Prediction\\nDevelop an end-to-end analytical infrastructure to facilitate real-time analytics, storage & water level prediction a 1,090km river in Kalimantan ft. deep learning, data engineering & analytics engineering\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Study: Adaro Predictive Maintenance \\nHow Supertype & PT. Saptaindra Sejati (Adaro) built a comprehensive predictive maintenance system that shaves millions off maintenance cost each year\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n\\n\\n\\nCase Study: AdColony (Opera)\\nTaking advertising operations and monetisation to the next level using a range of machine learning techniques, ft. unsupervised learning, deep learning\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Study: Creadits\\nSupertype\\'s data scientists and Creadits combined to produce advertising creatives that are 40% more performant, powered by deep insights into ad creatives\\' lifespan, ft. Supertype Summary, unsupervised learning\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Study: Programmatic Media Buying\\nProgrammatic audience creation through a bespoke machine-learning-as-an-API service, so media buying on RTB (real-time buying) exchanges are timely and with a stream of pre-qualified audience.\\n\\n\\n\\n\\n\\n\\n\\n\\nMore Data Science Consulting Case Studies\\n\\n\\n\\n                                new\\t\\t\\t\\t\\t\\t    \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\nAbout Supertype Our Team\\n\\nContact\\n\\n\\n\\n\\n\\n\\n\\nX\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nUnveiling YouTube Insights – Introduction, Data Collection, Data Processing, and Database (Part 1) \\nLeave a Comment \\r\\n\\r\\n\\t\\t\\t / notes, knowledge / By  \\nGeraldus Wilsen\\n\\n\\n \\n\\n\\nUnveiling YouTube Insights – Introduction, Data Collection, Data Processing, and Database (Part 1)\\n\\nIntroduction\\nWe, as programmers, are witnessing the rise of the Large Language Model (LLM) as the latest trend. Data scientists, software engineers, and even website or mobile developers are all captivated by its potential. When we can seamlessly integrate LLM into our products, it becomes a truly exciting prospect. Now, you might wonder, “How can we achieve this?” or “Isn’t building AI products costly?” Well, let me assure you, it’s a resounding “NO”! After reading this article, we’ll discover how we can create our very own AI app for free and with utmost ease. Let’s dive in!\\nFor this first project, we will be utilizing data from YouTube. Now, for a second, I want us to positioning ourself as a YouTube creator. Nowadays we can track metrics like views, watch time, audience demographics, traffic sources, and more in ease through YouTube studio. However, to grow our YouTube channel we need to know what people say about our content through their comment, right? What’s their feedback, what they like from our video, and many more. On the other hand, right now Youtube Studio hasn’t provided a tool to summarize those comment, if we only have 50 comments in our content, we can read it one by one. But how if our channel keeps growing, you upload more than 3 videos each week and more than 100 comments we will receive everyday. If we keep analyzing manually, we’ll waste our valuable time.\\nThat’s why today our mission is to help every Youtube content creator out there to easily analyzing their comment and gain insight from it in a minute using help of Large Language Model. Speaking of YouTube data, I highly recommend you checking out an article on data engineering authored by my colleague, Timotius. This series delves into data engineering using Airflow, offering valuable insights into the subject.\\nWorkflow and Pre-requisites\\nOkay, let’s get back to the topic! Before we start, I want to explain briefly how’s our website work\\n\\nUser input a link of a YouTube video – part 1\\nScrap the statistic and comment – part 1\\nStore it to database – part 1\\nUser can start a conversation with AI bot ( build with Langchain and Hugging Face Open Source Model) – part 2\\n\\nIn this article, I will more focus explaining about the backend side explaining on how it’s working. Mainly using Django, Django REST Framework, and Langchain. If you haven’t known it yet, I really recommend you to watch this video before continue:\\n\\nLangchain: LangChain & LLM tutorials (ft. gpt3, chatgpt, llamaindex, chroma) by Samuel Chan\\nDjango: Django Crash Course – Introduction + Python Web Development Tutorial by Caleb Curry\\nDjango REST Framework: Django REST Framework – Build an API from Scratch by Caleb Curry\\n\\nFor the frontend part, we are going to use Tailwind CSS, HTML, and JavaScript. Please feel free to check out my GitHub repository. I encourage you to explore and develop it further with your own design style, as I’m sure the talented audience reading this article can enhance it in amazing ways. If you are ready, let’s start with the first part, which focuses on data collection, data processing, and database\\nData Collection, Data Processing, and Database\\nIf you still remember the workflow of our website, the first step is to submit a YouTube video link. Using this link, we will perform a scraping task, which involves the process of data collection. Scraping YouTube data is relatively straightforward; what we actually need is a YouTube API key. Our team at Supertype has provided you with a quick tutorial, which you can access here:\\n\\nPart 1: YouTube Analytics API with Python (May 2022 new Google API Library)\\nPart 2: YouTube Comments to CSV\\nGithub Repo: youtube_api_python\\n\\nIn this section, we will modify some parts of the code to meet our specific requirements.\\n\\nCreate a new project in Google Cloud Console\\n\\nGo to Google Cloud Console\\nClick “Select a Project” dropdown beside the Google Cloud icon in the top right of your screen\\nClick “New Project” and fill the form with the project name and location\\n\\nClick the “create” button\\n\\n\\nCreate a YouTube API Key\\n\\nGo to https://console.cloud.google.com/apis/library/youtube.googleapis.com\\nClick “Enable”\\nClick “Create Credentials” and choose “API Key”.\\n\\nOnce you click it, you will get a pop up. This is your secret API Key, copy and save it to an environment variable or .env file so it will not leak.\\n\\n\\nWrite a function to scrap video statistic\\nasync def video_stats(youtube, videoIDs, channelID = None, to_csv=False):\\n    if type(videoIDs) == str:\\n        videoIDs = [videoIDs]\\n\\n    stats_list = []\\n\\n    for videoId in videoIDs:\\n        request = youtube.videos().list(\\n            part=\"snippet, statistics, contentDetails\",\\n            id=videoId\\n        )\\n        response = request.execute()\\n        statistics = response[\\'items\\'][0][\\'statistics\\']\\n        snippet = response[\\'items\\'][0][\\'snippet\\']\\n        statistics[\\'videoId\\'] = videoId\\n        statistics[\\'title\\'] = snippet[\\'title\\']\\n        statistics[\\'description\\'] = snippet[\\'description\\']\\n        statistics[\\'publishedAt\\'] = snippet[\\'publishedAt\\']\\n        statistics[\\'duration\\'] = response[\\'items\\'][0][\\'contentDetails\\'][\\'duration\\']\\n        statistics[\\'thumbnail\\'] = snippet[\\'thumbnails\\'][\\'high\\'][\\'url\\']\\n        statistics[\\'channelId\\'] = channelID\\n        statistics[\\'likeCount\\'] = statistics.get(\\'likeCount\\', 0)\\n\\n        print(f\"Fetched stats for {videoId}\")\\n        stats_list.append(statistics)\\n\\n    return statistics\\nLet’s walk through the code section by section to gain a better understanding of the implementation.\\nasync def video_stats(youtube, videoIDs, channelID=None, to_csv=False):\\nThis line defines an asynchronous function called video_stats. It takes four arguments: youtube (presumably an object representing the YouTube API client), videoIDs (a list of video IDs or a single video ID as a string), channelID (an optional channel ID, defaulting to None), and to_csv (an optional argument, defaulting to False).\\nif type(videoIDs) == str:\\n    videoIDs = [videoIDs]\\nThis checks if the videoIDs is a string. If it is, it converts it into a list containing just that string. This step ensures that the videoIDs parameter can be treated as a list, regardless of whether it was passed as a single string or a list of strings.\\nstats_list = []\\nThis initializes an empty list called stats_list, which will be used to store the statistics data for each video.\\nfor videoId in videoIDs:\\n    request = youtube.videos().list(\\n        part=\"snippet, statistics, contentDetails\",\\n        id=videoId\\n    )\\n    response = request.execute()\\nThis starts a loop that iterates through each videoId in the videoIDs list. Within the loop, it creates a request to the YouTube API to get video details (snippet, statistics, and contentDetails) for the current videoId. The request is executed using request.execute() which sends the request to the YouTube API and gets the response.\\nstatistics = response[\\'items\\'][0][\\'statistics\\']\\nsnippet = response[\\'items\\'][0][\\'snippet\\']\\nThese lines extract the ‘statistics’ and ‘snippet’ information from the API response for the current video.\\nstatistics[\\'videoId\\'] = videoId\\nstatistics[\\'title\\'] = snippet[\\'title\\']\\nstatistics[\\'description\\'] = snippet[\\'description\\']\\nstatistics[\\'publishedAt\\'] = snippet[\\'publishedAt\\']\\nstatistics[\\'duration\\'] = response[\\'items\\'][0][\\'contentDetails\\'][\\'duration\\']\\nstatistics[\\'thumbnail\\'] = snippet[\\'thumbnails\\'][\\'high\\'][\\'url\\']\\nstatistics[\\'channelId\\'] = channelID\\nstatistics[\\'likeCount\\'] = statistics.get(\\'likeCount\\', 0)\\nHere, specific data from the API response is extracted and added to the statistics dictionary for the current video. videoId, title, description, publishedAt, duration, thumbnail, and channelId are taken from the snippet information. likeCount is extracted from the ‘statistics’ dictionary, and if it is not present, it defaults to 0 using the .get() method.\\nprint(f\"Fetched stats for {videoId}\")\\nstats_list.append(statistics)\\nreturn stat_list\\nThis line prints a message indicating that the statistics for the current video with videoId have been fetched. Then, the statistics dictionary for the current video is appended to the stats_list, which collects data for all videos and being returned\\nWrite a function to process comment of the video\\ndef process_comments(response_items, channelID = None, csv_output=False):\\n    comments = []\\n\\n    for res in response_items:\\n\\n        # loop through the replies\\n        if \\'replies\\' in res.keys():\\n            for reply in res[\\'replies\\'][\\'comments\\']:\\n                comment = reply[\\'snippet\\']\\n                comment[\\'commentId\\'] = reply[\\'id\\']\\n                comments.append(comment)\\n        else:\\n            comment = {}\\n            comment[\\'snippet\\'] = res[\\'snippet\\'][\\'topLevelComment\\'][\\'snippet\\']\\n            comment[\\'snippet\\'][\\'parentId\\'] = None\\n            comment[\\'snippet\\'][\\'commentId\\'] = res[\\'snippet\\'][\\'topLevelComment\\'][\\'id\\']\\n\\n            comments.append(comment[\\'snippet\\'])\\n\\n    keytoremove = [\\'textDisplay\\',\\'authorProfileImageUrl\\',\\'authorChannelUrl\\',\\'authorChannelId\\',\\'canRate\\',\\'viewerRating\\',\\'likeCount\\',\\'updatedAt\\',\\'parentId\\']\\n    for i in comments:\\n        for y in keytoremove:\\n            del i[y]\\n\\n    new_comments = []\\n    for original_dict in comments:\\n        new_dict = {\\n            \\'video_id\\': original_dict[\\'videoId\\'],\\n            \\'comment_id\\': original_dict[\\'commentId\\'],\\n            \\'date\\': original_dict[\\'publishedAt\\'],\\n            \\'author\\': original_dict[\\'authorDisplayName\\'],\\n            \\'comment_text\\': original_dict[\\'textOriginal\\']\\n        }\\n        new_comments.append(new_dict)\\n\\n    new_key = \\'channel_id\\'\\n    new_value = channelID\\n\\n    for dictionary in new_comments:\\n        new_dict = {new_key: new_value}\\n        new_dict.update(dictionary)\\n        dictionary.clear()\\n        dictionary.update(new_dict)\\n\\n    def sentiment(i):\\n        blob = TextBlob(i)\\n        score = blob.sentiment.polarity\\n        if score == 0:\\n            sentiment = \\'neutral\\'\\n        elif score > 0: \\n            sentiment = \\'positive\\'\\n        else:\\n            sentiment = \\'negative\\'\\n\\n        return sentiment\\n\\n    for comment in new_comments:\\n        if type(comment[\\'comment_text\\']) == \\'float\\':\\n            comment[\\'sentiment\\'] == \\'no sentiment for numerical values\\'\\n        else:\\n            comment[\\'sentiment\\'] = sentiment(comment[\\'comment_text\\'])\\n\\n    print(f\\'Finished processing {len(new_comments)} comments.\\')\\n    return new_comments\\nThis function takes three parameters:\\n\\nresponse_items: A list of YouTube API response items containing comments data.\\nchannelID (optional): An identifier for the YouTube channel associated with the comments.\\ncsv_output (optional): A boolean flag indicating whether the comments should be saved to a CSV file.\\n\\nThe function performs the following tasks:\\n\\nIt processes the input response_items list to extract relevant information from the comments and replies.\\nIt removes unnecessary keys from the comment data using the keytoremove list.\\nIt constructs a new list of comments in a specific format, containing attributes like video ID, comment ID, date, author, and comment text.\\nIt calculates the sentiment of each comment text using the TextBlob library. sentiment(i): This is a nested function within the process_comments function. It takes a string i as input and calculates the sentiment of the text using TextBlob. The sentiment is categorized as “positive,” “negative,” or “neutral” based on the polarity score of the text.\\nIt prints the number of processed comments.\\nIt returns the processed comments as a list of dictionaries.\\n\\n\\nWrite a function to scrap comment of the video\\nIn this function, we will also use process_comment function that has been defined before.\\nscraped_videos = {}\\n\\nasync def comment_threads(youtube, videoID, channelID=None, to_csv=False):\\n\\n    comments_list = []\\n\\n    try:\\n        request = youtube.commentThreads().list(\\n            part=\\'id,replies,snippet\\',\\n            videoId=videoID,\\n        )\\n        response = request.execute()\\n    except Exception as e:\\n        print(f\\'Error fetching comments for {videoID} - error: {e}\\')\\n        if scraped_videos.get(\\'error_ids\\', None):\\n            scraped_videos[\\'error_ids\\'].append(videoID)\\n        else:\\n            scraped_videos[\\'error_ids\\'] = [videoID]\\n        return\\n\\n    comments_list.extend(process_comments(response[\\'items\\'],channelID))\\n\\n    # if there is nextPageToken, then keep calling the API\\n    while response.get(\\'nextPageToken\\', None):\\n        request = youtube.commentThreads().list(\\n            part=\\'id,replies,snippet\\',\\n            videoId=videoID,\\n            pageToken=response[\\'nextPageToken\\']\\n        )\\n        response = request.execute()\\n        comments_list.extend(process_comments(response[\\'items\\'],channelID)) \\n\\n    print(f\"Finished fetching comments for {videoID}. {len(comments_list)} comments found.\")\\n\\n    if scraped_videos.get(channelID, None):\\n        scraped_videos[channelID].append(videoID)\\n    else:\\n        scraped_videos[channelID] = [videoID]\\n\\n    comment_df = pd.DataFrame(comments_list)\\n\\n    return comment_df\\n\\nThis is an asynchronous function used to fetch comments for a specific YouTube video and process them using the process_comments function. It takes the following parameters:\\n\\nyoutube: The YouTube API client used to make requests.\\nvideoID: The ID of the YouTube video for which comments need to be fetched.\\nchannelID (optional): An identifier for the YouTube channel associated with the video.\\nto_csv (optional): A boolean flag indicating whether the comments should be saved to a CSV file.\\n\\nThe function performs the following tasks:\\n\\nIt makes an API request to fetch the comment threads for the given videoID.\\nIt processes the retrieved comments using the process_comments function.\\nIf there are more comments available (i.e., additional pages), it continues fetching them until there are no more comments.\\nIt prints the number of fetched comments and stores the list of video IDs with their associated channel IDs in the scraped_videos dictionary.\\nIt returns a pandas DataFrame containing the processed comments.\\n\\nPlease note that for the code to work, it requires the necessary libraries, such as pandas and TextBlob, and a YouTube API client initialized with the required credentials. Additionally, the TextBlob class needs to be imported from the textblob library at the beginning of the code.\\nWrite a function to summarize positive and negative comments\\nIn this part, we will not be developing a model from scratch to summarize a text; instead, we will utilize an open-source model from Hugging Face. This approach is entirely free; however, it is important to be aware that there are limitations on the free plan. Therefore, I will present three different ways to summarize the text, along with the pros and cons of each method. But before we proceed, let’s set up the Hugging Face model. Please ensure that you have installed langchain and Hugging Face libraries.\\nFor this case, I have chosen to use the Falcon 7B instruct model, which is one of the best open-source models available in those parameters. The results it provides are quite good. However, if you desire even better results, you may consider trying the OpenAI model or using higher parameters such as the Falcon 40B instruct model or llama2 (though, be mindful that you need to have compatible resources for these higher-parameter models).\\nfrom langchain import HuggingFaceHub\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain.chains.summarize import load_summarize_chain\\nfrom langchain import PromptTemplate,  LLMChain\\nimport textwrap\\nfrom transformers import pipeline\\n\\nload_dotenv(find_dotenv())\\nHUGGINGFACEHUB_API_TOKEN = os.environ[\"huggingfacehub_api_token\"]\\n\\nrepo_id = \"tiiuae/falcon-7b-instruct\"  \\nfalcon_llm = HuggingFaceHub(\\n    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_new_tokens\": 425}\\n)\\n\\nUsing load_summarize_chain from Langchain\\nasync def summary_of_comments(df,things = \\'positive\\'):\\n    filtered_comment = df[df[\\'sentiment\\'] == things]\\n    comment_text = \\';\\'.join(filtered_comment[\\'comment_text\\']).replace(\\'n\\',\\'\\')\\n\\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\\n    comment_doc = text_splitter.create_documents([comment_text])\\n\\n    chain = load_summarize_chain(falcon_llm, chain_type=\"map_reduce\", verbose=True)\\n    print(chain.llm_chain.prompt.template)\\n    print(chain.combine_document_chain.llm_chain.prompt.template)\\n\\n    output_summary = chain.run(comment_doc)\\n    wrapped_text = textwrap.fill(\\n        output_summary, width=100, break_long_words=False, replace_whitespace=False\\n    )\\n    print(wrapped_text)\\n\\n    return wrapped_text\\nIn short, this code will separate the text into chunks. We need to split it since there’s a limit on the number of tokens that can be processed at the same time. Once we split it into chunks, we save it as a document using comment_doc = text_splitter.create_documents([comment_text]). Then, we use load_summarize_chain to summarize the text.\\nUsing this approach, you will get a very comprehensive summary that doesn’t lose the context. However, if your text is too long, this method will incur significant costs in terms of both money and time. If you don’t have compatible resources, your website may end up crashing or encountering errors due to the processing time.\\nUsing combination of Langchain and Question Answering model\\nWe have reviewed the drawbacks of the previous method. Now, let’s explore an alternative solution that could potentially address the cost and time consumption issues. Instead of sending the entire text to the Langchain and Falcon 7B model, we can leverage a question-answering model to identify key points from each text. For this purpose, we are utilizing the prompt, “What {things} things does the user/audience feel?” However, it’s essential to keep in mind that this prompt can be modified in the future to potentially achieve better results.\\nOnce we have extracted the key points using the question-answering model, we can pass them to our Langchain model for summarization.\\nThis approach significantly reduces both cost and processing time. However, it’s worth noting that the results may not always be as satisfactory compared to the first method, where the Falcon 7B instruct model was applied directly to the entire text.\\nThe choice between these two methods depends on your specific requirements. If you need highly accurate and satisfying results, particularly for production or when selling it as a product where customer satisfaction is crucial, you might opt for the first method or consider investing more to achieve better results. On the other hand, if you are looking for a more cost-effective and time-efficient solution and the results do not have to be perfect, the second method could be a suitable option. It strikes a balance between cost and accuracy and may suffice for certain use cases.\\nrm = \\'deepset/roberta-base-squad2\\'\\n\\nquestion_answerer = pipeline(\"question-answering\", model=rm)\\n\\nasync def summary_of_comments(df,things = \\'positive\\'):\\n\\n    print(f\"start summary of {things} comments\")\\n\\n    filtered_comment = df[df[\\'sentiment\\'] == things]\\n\\n    if len(filtered_comment) != 0:\\n\\n        comment_text = \\';\\'.join(filtered_comment[\\'comment_text\\']).replace(\\'n\\',\\'\\')\\n\\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\\n        comment_doc = text_splitter.create_documents([comment_text])\\n\\n        output = {}\\n        for i in comment_doc:\\n            result = question_answerer(question= f\"What {things} things does the user/audience feel?\", context= i.page_content) #str(i)\\n            output[result[\\'answer\\']] = round(result[\\'score\\'], 4)\\n            print(f\"Answer: \\'{result[\\'answer\\']}\\', score: {round(result[\\'score\\'], 4)}, start: {result[\\'start\\']}, end: {result[\\'end\\']}\")\\n\\n        keys_set = set(output.keys())\\n        keys_sentence = \\'; \\'.join([key for key in keys_set])\\n        print(keys_sentence)\\n\\n        docs = text_splitter.create_documents([keys_sentence])\\n        print(\\'done splitting\\')\\n\\n        chain = load_summarize_chain(falcon_llm, chain_type=\"map_reduce\", verbose=True)\\n        print(chain.llm_chain.prompt.template)\\n        print(chain.combine_document_chain.llm_chain.prompt.template)\\n\\n        output_summary = chain.run(docs)\\n        wrapped_text = textwrap.fill(\\n            output_summary, width=100, break_long_words=False, replace_whitespace=False\\n        )\\n        print(wrapped_text)\\n\\n        print(f\"done summary of {things} comments\")\\n\\n        return wrapped_text\\n\\n    else:\\n        return f\"There is no {things} comment\"\\n\\n\\n\\nWrite a final function to wrap up the statistics and comment functions\\nasync def get_result(url, youtubeapikey):\\n    parsed_url = urlparse(url)\\n    query_params = parse_qs(parsed_url.query)\\n    videoid = query_params.get(\\'v\\', [\\'\\'])[0]\\n\\n    youtube = build(\"youtube\", \"v3\", developerKey= youtubeapikey)\\n\\n    stats = await video_stats(youtube, videoid)\\n    df = await comment_threads(youtube, videoID=videoid)\\n    positive = await summary_of_comments(df,\\'positive\\')\\n    negative = await summary_of_comments(df,\\'negative\\')\\n    neutral = await summary_of_comments(df,\\'neutral\\')\\n\\n    return stats,df,videoid,positive,negative, neutral\\n\\nget_result is our final function that will be used in our Django code. As you may recall, in our previous function, we required a YouTube API Key and the link to the YouTube video. These two values are processed when the user submits the form, and then we utilize the get_result function to process them. If you don’t fully understand the process now, that’s okay; it will be our next step. I want you to keep it in mind. Once we finish this main code, we will explore the form and Django.\\nHTML Form\\n<form action = \"getoutput\" method = \"POST\" id = \"form\" class = \"mt-3 text-center flex\">\\n    {% csrf_token %}\\n    <input\\n        type = \"text\"\\n        name = \"videoid\"\\n        placeholder = \"Paste your youtube video url here\"\\n        class = \"m-2 px-3 py-1.5 border shadow rounded w-5/6 text-sm placeholder:text-slate-400 focus:outline-none focus:ring-1 focus:ring-red-600 inline lg:text-lg\">\\n    <input\\n        type = \"submit\"\\n        class = \"m-2 px-3 py-1.5 rounded text-sm bg-red-600 text-white transition duration-300 ease-in-out hover:bg-black hover:shadow-lg lg:text-lg dark:hover:bg-white dark:hover:text-black\">  \\n</form>\\n\\nThis snippet is from the complete home.html, which includes the form where users can submit a YouTube video link. The key elements that connect this HTML form with our backend are the action, method, and name attributes. Here are the details:\\n\\nAction: “getoutput” is the name of our Django function. By specifying this in the form tag, we inform the HTML which function to execute when the user submits the form.\\nMethod: We use “POST” since we are uploading or posting new data or records to our backend. This method serves as a signal to Django, indicating that we want to create a new resource on the server with the data provided in the form. (More details about how Django handles different HTTP methods will be covered later.)\\nName: “videoid” is the name attribute that represents the value being passed to our backend. This name is used to identify and access the submitted data on the server side.\\n\\nWhen creating a form in Django, it’s important to remember that you need a CSRF token. The CSRF (Cross-Site Request Forgery) attack can trick the user’s browser into executing unwanted actions on an authenticated website. To prevent such attacks, Django includes a built-in security mechanism called the CSRF Token. This unique and unpredictable token is generated for each user session and is included as a hidden field in the form using the {% csrf_token %} template tag. Upon form submission, the CSRF Token is sent back to the server with the form data, and Django checks its validity. If the token is missing or incorrect, the request is rejected, safeguarding against potential CSRF attacks. In summary, including the CSRF Token in your HTML forms is essential to ensure the authenticity of form submissions and protect the integrity of your Django application.\\nDjango Model / Database (models.py)\\nIf you look your folder structure, inside your Django app, you will see models.py. This python file is a place for us to write a Django Model or database. Here are two databases that we will create together.\\n\\nApiKey Model: This model is used to store API keys associated with users. It has fields for the user (linked through a ForeignKey relationship), YouTube API key, OpenAI API key, and Hugging Face Hub API key.\\nResult Model: This model stores results related to YouTube videos. It includes fields for user, video ID, video title, views, likes, comments, positive/negative/neutral comments, and timestamps for creation and updates.\\n\\nfrom django.db import models\\nfrom django.contrib.auth.models import User\\n\\nclass ApiKey(models.Model):\\n    user = models.ForeignKey(User, on_delete=models.CASCADE)\\n    youtube_api_key= models.CharField(max_length=100, null=True, blank=True)\\n    openai_api_key = models.CharField(max_length=100, null=True, blank=True)\\n    huggingfacehub_api_key = models.CharField(max_length=100, null=True, blank=True)\\n\\nclass Result(models.Model):\\n    user = models.ForeignKey(User, on_delete=models.CASCADE)\\n    videoid= models.CharField(max_length=20, null=True, blank=True)\\n    videotitle= models.CharField(max_length=200, null=True, blank=True)\\n    view = models.CharField(max_length=20, null=True, blank=True)\\n    like = models.CharField(max_length=10, null=True, blank=True)\\n    comment = models.CharField(max_length=10, null=True, blank=True)\\n    total_positive_comment = models.CharField(max_length=10, null=True, blank=True)\\n    positive_comment = models.CharField(max_length=5000, null=True, blank=True)\\n    total_negative_comment = models.CharField(max_length=10, null=True, blank=True)\\n    negative_comment = models.CharField(max_length=5000, null=True, blank=True)\\n    total_neutral_comment = models.CharField(max_length=10, null=True, blank=True)\\n    neutral_comment = models.CharField(max_length=5000, null=True, blank=True)\\n    created_at = models.DateTimeField(auto_now_add=True)\\n    last_update = models.DateTimeField(auto_now=True)\\n\\n    def __str__(self):\\n        return self.videoid\\nAfter we have create a model or database, we should run two commands in our command prompt:\\n\\npython manage.py makemigrations: This command will analyze the changes we made to the models and create migration files in the migrations directory of our app.\\npython manage.py migrate: This command will execute the migrations and update the database schema to reflect the changes you made in your models.\\n\\n\\nRegister our Django model in admin.py\\nfrom django.contrib import admin\\nfrom .models import User, ApiKey, Result\\n\\n# Register your models here.\\nadmin.site.register(ApiKey)\\nadmin.site.register(Result)\\n\\nFill out our views.py\\nWe have register our database, so right now, let’s code. If you still remember the 3 key elements that connect the HTML form with our backend, we will use them here. The first one is the action “getoutput”. In our Django code, we create a POST function called “getoutput”, like the following code:\\ndef getoutput(request):\\n\\ncontext = {\\n    \\'user_id\\': request.user.pk\\n}\\n\\nif request.method == \"POST\":\\n    url = request.POST[\"videoid\"]\\n\\n    try:\\n        key = ApiKey.objects.get(user=request.user)\\n        youtubeapikey = key.youtube_api_key\\n        if youtubeapikey is None:\\n            youtubeapikey = os.environ.get(\\'youtubeapikey\\')\\n    except:\\n        youtubeapikey = os.environ.get(\\'youtubeapikey\\')\\n\\n    async def run_async():\\n        stats, df, videoid, positive, negative, neutral = await get_result(url, youtubeapikey, username, recipient_email)\\n\\n        source = {\\n            \\'videoid\\': videoid,\\n            \\'videotitle\\': stats[\\'title\\'],\\n            \\'view\\': stats[\\'viewCount\\'],\\n            \\'like\\': stats[\\'likeCount\\'],\\n            \\'comment\\': stats[\\'commentCount\\'],\\n            \\'total_positive_comment\\': len(df[df[\\'sentiment\\'] == \\'positive\\']),\\n            \\'total_negative_comment\\': len(df[df[\\'sentiment\\'] == \\'negative\\']),\\n            \\'total_neutral_comment\\': len(df[df[\\'sentiment\\'] == \\'neutral\\']),\\n            \\'positive_comment\\': positive,\\n            \\'negative_comment\\': negative,\\n            \\'neutral_comment\\': neutral,\\n        }\\n\\n        return source\\n\\n    loop = asyncio.new_event_loop()\\n    asyncio.set_event_loop(loop)\\n    source = loop.run_until_complete(run_async())\\n    loop.close()\\n\\n    current_user = request.user\\n    videoid = source[\\'videoid\\']\\n\\n    # Check if a record with the same videoid exists\\n    try:\\n        result = Result.objects.get(user=current_user, videoid=videoid)\\n        print(result)\\n    except Result.DoesNotExist:\\n        result = None\\n\\n    # If the record exists, update it; otherwise, create a new record\\n    if result:\\n        result.videotitle = source[\\'videotitle\\']\\n        result.view = source[\\'view\\']\\n        result.like = source[\\'like\\']\\n        result.comment = source[\\'comment\\']\\n        result.total_positive_comment = source[\\'total_positive_comment\\']\\n        result.positive_comment = source[\\'positive_comment\\']\\n        result.total_negative_comment = source[\\'total_negative_comment\\']\\n        result.negative_comment = source[\\'negative_comment\\']\\n    else:\\n        result = Result(\\n            user=current_user,\\n            videoid=videoid,\\n            videotitle= source[\\'videotitle\\'],\\n            view = source[\\'view\\'],\\n            like = source[\\'like\\'],\\n            comment = source[\\'comment\\'],\\n            total_positive_comment = source[\\'total_positive_comment\\'],\\n            positive_comment = source[\\'positive_comment\\'],\\n            total_negative_comment = source[\\'total_negative_comment\\'],\\n            negative_comment = source[\\'negative_comment\\']\\n        )\\n\\n    result.save()\\n\\n    return redirect(reverse(\\'chat\\') + f\\'?id={result.id}\\')\\n\\nelse:\\n    return render(request, \"home.html\", {\\'context\\':context})\\nThis code defines a Django view function named getoutput that handles a POST request. The primary purpose of this function is to fetch data about a YouTube video, perform sentiment analysis on its comments, and then store the results in a Django model named Result. Let’s break down the code step by step:\\n\\nThe context dictionary is initialized with the user’s ID, retrieved from the request.\\nThe function checks if the request method is POST (indicating form submission). If so, it extracts the video ID from the submitted form data.\\nAn attempt is made to retrieve the user’s YouTube API key from the ApiKey model. If not found, it falls back to using an API key from the environment variables.\\nAn asynchronous function named run_async is defined. This function retrieves statistics and sentiment analysis results for the given video URL and API key.\\nAn event loop is created using asyncio.new_event_loop() to execute the asynchronous function, and the loop is closed afterward.\\nThe current_user variable is assigned the user making the request, and the videoid is extracted from the source dictionary.\\nThe code checks if a Result record with the same videoid exists for the current user. If it exists, the record’s fields are updated with new data; otherwise, a new Result instance is created.\\nThe Result instance is saved to the database using result.save().\\nFinally, the function redirects the user to another view named \\'chat\\', passing the id of the stored Result record as a query parameter. More detail on this topic will be explained in part 2.\\nIf the request method is not POST (e.g., a GET request), the function renders the “home.html” template with the context data.\\n\\nThis view function serves as the backend logic for processing user input, fetching YouTube data, performing sentiment analysis, and storing the results in a Django model. It demonstrates how Django handles data manipulation, asynchronous operations, and database interactions in a web application.\\nAdd our getoutput view into urls.py\\nfrom django.urls import path\\nfrom . import views\\n\\nurlpatterns = [\\n    path(\\'\\', views.home, name=\"home\"),\\n    path(\\'getoutput\\',views.getoutput, name = \"getoutput\"),]\\n\\n\\nConclusion\\nIn this article, we embarked on a challenge to create a comprehensive web application that leverages the power of Django, sentiment analysis, and a Large Language Model to gain invaluable insights from YouTube comments. By blending data collection, analysis, and storage, we have built a tool that empowers content creators to better understand their audience’s sentiments and preferences. What’s most important, you now truly comprehend how to seamlessly integrate Large Language Models into our product, all for free and with ease.\\nAs we wrap up this initial phase, remember that the journey is far from over. Here’s a stimulating bonus challenge that will propel your skills to greater heights. Let’s shift gears and modify our approach. Instead of querying our database directly, we’re introducing a fascinating twist: the utilization of APIs.\\nTo embark on this challenge, follow these steps:\\n\\nBegin by installing Django REST Framework using the command pip install djangorestframework.\\nCreate a new file named serializers.py.\\nInside serializers.py, define a class named ResultSerializer.\\nIntegrate your serializers into view.py using the import statement from .serializers import ResultSerializer.\\nForge a path to access the API for CRUD operations; name it result.\\nAdd this new path to your urls.py configuration.\\n\\nSuccessfully completing this challenge will yield exciting results. When you type http://127.0.0.1:8000/result/1 into your browser, you’ll see a Django Rest Framework template and your data like this\\n\\nIn our upcoming Part 2, we’ll delve even deeper into the potential of Large Language Models and also Django REST Framework. We’ll pave the way for users to engage with an AI chatbot, enabling activities like seeking advice and exploring a myriad of other possibilities that an AI bot can seamlessly facilitate. This journey promises to unlock a realm of innovative interactions and dynamic user experiences.\\nRelevant Links\\n\\nProject Github: https://github.com/projectwilsen/ReviewAnalyzer/\\n\\n\\n\\n\\n\\nPost navigation\\n← Previous PostNext Post →\\n\\n\\n\\nLeave a Comment Cancel ReplyYour email address will not be published. Required fields are marked *Type here..Name*\\nEmail*\\nWebsite\\n Save my name, email, and website in this browser for the next time I comment.\\n \\n\\n \\n\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRequest A Call \\n\\n\\n\\nPlease enable JavaScript in your browser to complete this form.Name *FirstLastCompanyPhone Number *Work Email *Your work email, so we can reach you. We respect your privacy and do not engage in any spamming activities.PhoneGet in touch \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQuick Links \\n\\n\\n\\n\\n\\n\\n\\n \\nData Science Consulting\\n\\n\\n\\n\\n\\n \\nCase Study (Data Science & Engineering)\\n\\n\\n\\n\\n\\n \\nManaged Development\\n\\n\\n\\n\\n\\n \\nArticles\\n\\n\\n\\n\\n\\n \\n Supertype on Linkedin\\n\\n\\n\\nSupertype Products\\n\\n\\n\\n\\n                                                                 \\nSectors Financial Data Layer\\n\\n\\n\\n\\n\\n \\nSupertype Fellowship\\n\\n\\n\\n\\n\\n \\nSupertype Summary\\n\\n\\n\\n\\n\\n \\nSupertype Collective\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompany \\n\\n\\n\\n\\n\\n\\nSupertype International\\n\\n\\n\\nSupertype Pte. Ltd. (Reg. 202070707N)\\n\\n\\n160 Robinson Road #14-04 Singapore 068914\\n\\n\\n\\n\\n \\nContact Us\\n\\n\\n\\nSupertype Indonesia\\n\\n\\nPT. Supertype Teknologi Nusantara (Reg. 1250601)\\n\\n\\nOffice 8, Level 18-A, Jl. Jend. Sudirman Kav. 52-53 Sudirman Central Business District (SCBD) Lot.28\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright © 2024 Supertype | Supertype Pte Ltd (Registration 202070707N)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSitemap\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\t\\t\\t\\tGo to mobile version\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://supertype.ai/notes/unveiling-youtube-insights-part-1/\")\n",
    "pages = loader.load()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wikipedia Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'title': 'Sam Altman', 'summary': 'Samuel Harris Altman (born April 22, 1985) is an American entrepreneur and investor best known as the CEO of OpenAI since 2019 (he was briefly fired and reinstated in November 2023). He is also the chairman of clean energy companies Oklo Inc. and Helion Energy. Altman is considered to be one of the leading figures of the AI boom. He dropped out of Stanford University after two years and founded Loopt, a mobile social networking service, raising more than $30 million in venture capital. In 2011, Altman joined Y Combinator, a startup accelerator, and was its president from 2014 to 2019.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Sam_Altman'}, page_content='Samuel Harris Altman (born April 22, 1985) is an American entrepreneur and investor best known as the CEO of OpenAI since 2019 (he was briefly fired and reinstated in November 2023). He is also the chairman of clean energy companies Oklo Inc. and Helion Energy. Altman is considered to be one of the leading figures of the AI boom. He dropped out of Stanford University after two years and founded Loopt, a mobile social networking service, raising more than $30 million in venture capital. In 2011, Altman joined Y Combinator, a startup accelerator, and was its president from 2014 to 2019.\\n\\n\\n== Early life and education ==\\nAltman was born on April 22, 1985, in Chicago, Illinois, into a Jewish family, and grew up in St. Louis, Missouri. His mother is a dermatologist, while his father was a real estate broker. Altman is the eldest of four siblings. At the age of eight, he received his first computer, an Apple Macintosh, and began to learn how to code and take apart computer hardware. He attended John Burroughs School, a private school in Ladue, Missouri. In 2005, after two years at Stanford University studying computer science, he dropped out without earning a bachelor\\'s degree.\\n\\n\\n== Career ==\\n\\n\\n=== Early career ===\\nIn 2005, at the age of 19, Altman co-founded Loopt, a location-based social networking mobile application. As CEO, Altman raised more than $30 million in venture capital for the company, including an initial investment of $5 million from Patrick Chung of Xfund and his team at New Enterprise Associates, which was later followed by investments from Sequoia Capital and Y Combinator. In March 2012, after Loopt failed to gain traction with enough users, the company was acquired by the Green Dot Corporation for $43.4 million. The following month, Altman co-founded Hydrazine Capital with his brother, Jack Altman, which is still in operation.\\nAltman became a partner at Y Combinator, a startup accelerator that invests in a wide range of startups, in 2011, initially working there on a part-time basis. In February 2014, Altman was named president of Y Combinator by co-founder Paul Graham. In a 2014 blog post, Altman said that the total valuation of Y Combinator companies had surpassed $65 billion, including Airbnb, Dropbox, Zenefits and Stripe. In September 2016, Altman announced his expanded role as president of YC Group, which included Y Combinator and other units. Altman said that he hoped to expand Y Combinator to fund 1,000 new companies per year. He also tried to expand the types of companies funded by YC, especially \"hard technology\" companies. In October 2015, Altman announced YC Continuity, a $700 million equity fund investing in YC companies as they matured. A week earlier, Altman had introduced Y Combinator Research, a non-profit research lab, and donated $10 million to fund it. In March 2019, YC announced Altman\\'s transition from the president of the company to a less hands-on role as chairman of the board, for him to focus on OpenAI. This decision came shortly after YC announced it would be moving its headquarters to San Francisco. As of early 2020, he was no longer affiliated with YC. It was later reported that Altman was fired from YC and had appointed himself chairman without authorization.\\nAltman co-founded Tools For Humanity in 2019, a company that builds and distributes systems designed to scan people\\'s eyes to provide authentication and verify proof of personhood to counter fraud. People who agree to have their eyes scanned are compensated with a cryptocurrency called Worldcoin. Tools For Humanity describes its cryptocurrency as similar to universal basic income. A Hong Kong regulator directed Worldcoin to cease operations there because scanning and collecting iris and face images of the public using its devices was \"unnecessary and excessive\". \\nAltman has several other investments, in companies including Humane, the world\\'s first wearable computer powered by AI, Retro Biosciences, a research company aiming to ext'), Document(metadata={'title': 'Removal of Sam Altman from OpenAI', 'summary': \"On November 17, 2023, OpenAI's board of directors ousted co-founder and chief executive Sam Altman after the board had no confidence in his leadership.  The removal was caused by concerns about his handling of artificial intelligence safety, and allegations of abusive behavior.  Altman was reinstated on November 22 after pressure from employees and investors.\", 'source': 'https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI'}, page_content='On November 17, 2023, OpenAI\\'s board of directors ousted co-founder and chief executive Sam Altman after the board had no confidence in his leadership.  The removal was caused by concerns about his handling of artificial intelligence safety, and allegations of abusive behavior.  Altman was reinstated on November 22 after pressure from employees and investors.\\n\\n\\n== Background ==\\n\\n\\n=== OpenAI ===\\n\\nOpenAI is an artificial intelligence firm founded in December 2015 as a non-profit entity. The for-profit division of the organization released the chatbot ChatGPT in November 2022, contributing to a resurgence in generative artificial intelligence funding. The board of directors of the controlling non-profit formerly comprised chief scientist Ilya Sutskever, as well as Adam D\\'Angelo, chief executive of Quora, entrepreneur Tasha McCauley, and Helen Toner, strategy director for the Center for Security and Emerging Technology. As of October 2023, the company is valued at US$80 billion and was set to bring in US$1 billion in revenue. Altman has described OpenAI\\'s relationship with Microsoft as the \"best bromance in tech\".\\nOpenAI is uniquely structured, an intentional decision to avoid investor control. A board of directors controls the non-profit OpenAI, Inc. The non-profit owns and controls a for-profit company itself controlling a capped-profit company, OpenAI Global, LLC and a holding company owned by employees and other investors. The holding company is the majority owner of OpenAI Global, LLC.; Microsoft owns a minority stake in the capped-profit company. OpenAI\\'s bylaws, enacted in January 2016, allow a majority of its board of directors to remove any director without prior warning or a formal meeting with written consent.\\n\\n\\n=== Sam Altman ===\\n\\nSam Altman is a co-founder of OpenAI and its former chief executive; Altman took over the company following co-chair Elon Musk\\'s resignation in 2018. Under Altman, OpenAI has shifted to becoming a for-profit entity. Altman is credited with convincing Microsoft chief executive Satya Nadella with investing US$10 billion in cash and computing credits into OpenAI and leading several tender offer transactions that tripled the company\\'s valuation. Altman testified before the United States Congress speaking critically of artificial intelligence and appeared at the 2023 AI Safety Summit.\\nIn the days leading up to his removal, Altman made several public appearances, announcing the GPT-4 Turbo platform at OpenAI\\'s DevDay conference, attending APEC United States 2023, and speaking at an event related to Burning Man.\\n\\n\\n== Events leading up to the removal ==\\nThe resignation of LinkedIn co-founder Reid Hoffman, venture capitalist Shivon Zilis, and former Republican representative Will Hurd from the board allowed the remaining members to remove Altman. According to Kara Swisher and The Wall Street Journal, Sutskever was instrumental in Altman\\'s removal. Disagreements over the safety of artificial intelligence divided employees prior to Altman\\'s removal. The release of ChatGPT created divisions with OpenAI as a for-profit company without considerations for the safety of artificial intelligence and a non-profit cautious of artificial intelligence\\'s capabilities; in a staff email sent in 2019 and obtained by The Atlantic, Altman referred to these divisions as \"tribes\".\\nPrior to his removal, Altman was seeking billions from Middle Eastern sovereign wealth funds to develop an artificial intelligence chip to compete with Nvidia and courted SoftBank chairman Masayoshi Son to develop artificial intelligence hardware with former Apple designer Jony Ive. Sutskever and his allies opposed these efforts, viewing them as unjustly using the OpenAI name. Altman reduced Sutskever\\'s role in October 2023, furthering divisions; Sutskever successfully appealed to several members of the board. Swisher and The Verge reporter Alex Heath stated that opposition to Altman\\'s profit-driven strategy culminated in the DevDay conference i')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "query = \"Sam Altman\"\n",
    "pages = WikipediaLoader(query=query, load_max_docs=2).load()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. YouTube Transcript Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'KMXQ4SVLwmo'}, page_content=\"hey wison yeah what is knowledge craft do we need it to enhance our LM performance oh and also do you know how to integrate it with L chain okay guys hold on take it easy I will explain to you in detail step by step stuff from the per and how to set up our Na 4y databas and then how to integrate it using L chain and of course all of that we will use an open source all app so without further ado let get started what is no squas Once Upon a Time way back in 1736 there was a sweet M named Leonard eer who faced a mindbending challenge the seven breach of kbur problem is there a way to walk across all bries ones starting and ending at the same place eer heis something more crucial what matter was how things were connected so you turn the city's lanmark into dots or nodes and its preaches into lives for ages creating a neat little Network known as the origin of the graph Theory story time is both for SP hold on instead of just buing about landmarks and Brides now Las thing be so he mention notes as to the adjective such as people buildings schools bands and many more and that the ages as the relationship B them for example there is ammy working at a bank and chatting away in Mand now house and Brian also B bound who loves fried R oh there's also an Brian's friend who is btic for fried R too and also FL in Mandarin sounds a bit Tangled right but look at the graph we have got suddenly all starts to make SS now with the idea of notes and ages and the team in relationship with this VRA hey let's get our world is not just a and Amy and Brian it's not just about B and fr price too right so it's a fast thrill of people teams ads and all of those have this special relationship and that's what we call as a knowledge craft so once again knowledge craft is a network of real world entities and and illustrates the relationship between them over we store the no scub in a graph database such as na Forge database and process it using cyber query language n cyber query language includes claes like use match read rer and more you can delve into them further with this new 4G chit now let's talk about how ncft EMP powering alen so using a noge graph you can identify the links even Sly disconnected C what do it means so February 2024 researchers from Microsoft conducted a research to compare Bas retrieval out Meed generon system or rack and graph rack danus filot incident information for a news article data set and the posit questions what has no forus yet done the result baseland white not able to answer it because sometimes using factor is not was a facted especially when the query does not provide enough context about its true intent or when the context is fragment across large corus of tax you probably have hearded about Plus in the middle things and that's the problem and they Pro that gra able to answer this questions because first the about entities which has no FIA this allows the El them to gr itself and then provide a fair to answer in November 2023 there is also a resarch that show how noge gra optimize the SE in a SQL database the researchers revealed that question answering using gbd4 with zero shut problems directly on SQL database achieves an accuracy of 16% notably this accuracy increases 54% when questions are posed over a Knowledge Graph representation on the Enterprise SQL database okay so that's the reason why learn knowledge SC our LM is very interesting and important and before we go into code it's better for us to understand how it works so first in here we will get the user question and then we'll pass this user question to our LM in this TP our LM will also receive a database schema database schema means like the entities and relationship that we already Store to our new forg database and the whole process in here we call it as the graph chain and then from the graph team it will generate a cyber query and then we will run the Cyber query to our new for database to get a result and the result we will pass it to the LM in here the LM will pass the result we create result into our final answer and this St we will get the final one okay th the Cod so actually all the code the data I've already provided in this GitHub and I already put it in the description so the first thing that we need to do is just to clone this so just copy and then go to our FAS code and do K Club here okay guys what stand our next St will be creating a virtual environment so just go to our folder and then do pip install it this it will take a few seconds so I will skip this part now let's open the notep that we have in here so since three already installed all the buttons they from the install that we've just done before so let's run this one so in here all go say we going to use open source L which is the Gemini and then having face and also near so I'll go work on how to get the API for all this but before that we need to cre F to sa B variable and just do this the Google API key so just go over this URL and then or create API if you can have it and for Hing face just follow this link and then use new token but since I already have this tokens so just copy and then save our envirment fre aable and for near forg actually can use my near forg desktop or for this I'll use near hour is uh little simpler so if you don't have a con you should sign up in here okay so the instant is ready and now like click open okay so in here we have the connection URL in here we have the database user and also password make sure to also copy the connection URL and the database username to the environment variable the file so right next is copy paste the password and like connect now the database is connect connected and now the next test is how to connect the python in here to the our database in n4g so actually lch ready provide us with a very simple connector which is this one lch Comm manity to C na for C here so just click run it's all done okay guys so we have done to set up everything so now let's talk about the data itself so the data that we will use in here I will keep it simple we won process a data from the unstructured format such as the PDF the text file no but in here we will use from data from Koo so that is for Manus Kumar for providing this data set so basically is a Linkin data set at professional information like the me the CP and and caring company that they work in the position and many more and actually year we did a little bit preprocessing to finally get this final data the next thing is how to insert this data to na for database so as you can see here says our data in na forg is still empty to know zero and the relationship zero and you can also check it by run to cell you can in here there's nothing in here so how to input it so the first thing that in here is by using the Cyber query to interact with our databit now I'll explain one by one startop from here load CSV with headers from blah blah blah blah so actually it's loading the CSV file from this gith repository and then as R me file for each row and in here is a cyber query inside so we known that okay in here name is the entity of name is person so we make it to Define The Entity that we have in our database so here it's a little bit different with the previous one right so basically we use for is because if you see in the language in here sometimes one people speaks man languages such as Roberto Mira he can speaks English Italian France Dutch and German so here we separate with this s and this line is talking about the relationship if you don't remember about the explanation about relationship entity so this one is the relationship or the ages just run this one okay and let's check it okay so now our data is already in the Nao forg database and check once again let's reload this okay see now we have the company now we have ocated at Country industrial language all the data in from CSP is already imputed in our NE for okay guys now let's talk about the most interesting part of this video how to operate the light L model to interact with our knowledge gra in NE so here we are using chap Google generative AI German Pro open source and then the API can here is the parameter that we have saved if we in file and in here we set the temporate to zero the question is why do you not set it to 0.5 or 0.9 the reason is because in this test we need the LM not to do a creative writing but we needed to translate the natural language to a cyber query language and then here the chain with the chain with graph cyber Q L has provided very easy to use so the graph is the graph that we have defining here and LM is the model that we want to use and for both I set it to close through what does it mean because I want to understand what happened Beyond LOL so right to and then in here we have several questions I've already created a table that contains a pair of the question and the correct answer so it becomes easier for us to check whether the answer resulted from the LM is correct or not we want to know how it's perform so let's run it okay that's cool okay so now let's talk how about result so the first questions L companies and advertising Serv industry in here it gener that cyber Under full contacts is said and J is Tob creative B advertising that's perfect and the second question is a working graduated from cyber FR University is currently employed at okay I'm not sure why but the J cyber query in here look a bit messy and that's why there's a no in the Contex are the result is I do not have the information we filed here and then the third question where is Power LS working okay so sure the J cyber query is correct and the full contact in here tobox cre if this is correct but I don't sure why the Finish Ching here IEM at the answer the four questions we see po here which actually if you remember about the schema of our database the relationship there's no spoken in in our database right so that's why it's no and I didn't have that information the last one is okay problem is the same is not actually it's kind of hting about relationship by the properties by entities right because we don't have relationship is native of in our schema so that's why it's also wrong the answer is zero the correct answer is one now let's do quick recap the result that we have got before so here we have two correct answer and three false answer from the elet right and from this result we can identify some problems the first one is not being able to accurately translate text into a cyber query and the second one is hallucinates properties relationship and entities this one is one of the biggest problems in llm in generating a cyber query so what's the solution we called it as prompting strategies so in short we provide examples to our model to help it understand the structure correctly similar to how parents guide us when we learn to work right more examples makes the models learns and smarter now let's jump to code so the first thing that we need to do is to create pairs of question and sever query so I do it manually just copy this and paste the jity okay once we got a result so just copy and paste it to our psod for example in here I want to copy this questions and the most important part is to treat attack once again if the jtic query from the jity is already not we can do this by going to our new copy paste and check okay good we have this the C queries right just do all that and copy ping here the last thing that you need to do is to add places in here because if you don't do it you I've already have this one so I won't use it I'll use mine to this friends and in here actually langin already provide us with a f shot prom template and so prom template this is the problem that we want to use that we use as a parameter in here and the example is is example that we have already divid in here so it will take the top three examples from it and then the perfect s and here is the input variables which is equation and schema we'll use it equation in this and the schema in here so run this one this is the example of the problem let's create our second change and check this for the first question the answer is correct to box creative big advertising into people school and for the second question we get a correct answer which is elastic pad and in here we got toolbox creative but the four question the Gen cqu is also correct and we get here fali new and then for the last one okay we got a card corre answer though which is one so using the problem strategies will enhance our model right now we have all correct answer okay guys our job is done but as I've told you before that I have a bonus for you so if you're still remember we have this question where do Michael work and the problem that we got is which workers friends what industries a workers named animal associated with and we workers live in Canada and speak German so actually there's no correlation right between which workers friend and where do Michael and the reason is this line so in here we are taking top three from this list in fact we have more than three questions so what's the point to just only take this top three and that's why we need a dynamic problem so to create a dynamic problem we need a semantic similarity example selector so basically you calculate which one is the closest between the question and the Leist that we have so the first one that you need is the haing fees eddings and then the for Factor so previously we are taking the top three question from the examples list now we will use the example selector to create a dynamic Pro if you run this so where do Michael work what companies the workers named John working it's makes sense where the workers named Alice live and and what industrious of workers named amul Associated so right now the generative prom is more Dynamic and we're not just take top three from our list okay guys so we have learned about what is NOLA gr why is it important how to set up our data in May for database how to chat with our data using lank chain and open source Lam and last but not least how to enhance our model I hope this video is useful for you guys and if you have any thoughts pleas for commment so please let me know in the comment section below bye-bye\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "loader = YoutubeLoader.from_youtube_url(\"https://youtu.be/KMXQ4SVLwmo\", add_video_info=False)\n",
    "pages = loader.load()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Summarize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/llm/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/hoang/miniconda3/envs/llm/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "query = \"Tim Cook\"\n",
    "raw_documents = WikipediaLoader(query=query, load_max_docs=20).load()\n",
    "# raw_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw_documents = [raw_documents[i] for i in [0,1,4,7,8,9,10,12,13]] #0: Tim Cook (person), 1: Apple (company), 4: Mac (product), 10: Research, 11: Apple Maps, 13: App Store, 7: Apple TV, 8: Steve Jobs, 13: iPhone\n",
    "docs = \" \".join([d.page_content for d in filtered_raw_documents]).replace(\"\\n\", \"\").replace(\"==\", \"\")\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=30\n",
    ")\n",
    "split_docs = text_splitter.create_documents([docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/hoang/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# llm = Ollama(model=\"mistral\") # Define the mistral model\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "# Define the map prompt template\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{all_data}\n",
    "Based on this list of docs, please find the important information from it (focus on entities and relationship)\n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "\n",
    "# Define the map_chain\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{all_data}\n",
    "Take these and distill it into a final, consolidated summary of the main themes. In one final paragraph\n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain,\n",
    "    document_variable_name=\"all_data\"  # This should match the variable name in reduce_prompt\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=1024,\n",
    ")\n",
    "\n",
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"all_data\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Run the MapReduce Chain\n",
    "summarization_results = map_reduce_chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./clean_data/clean_summary.txt\"\n",
    "\n",
    "with open(file_path, 'a') as file:\n",
    "    file.write(summarization_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = ['person','school','award','company','product','characteristic']\n",
    "relation_types = ['alumniOf','worksFor','hasAward','isProducedBy','hasCharacteristic','acquired','hasProject','isFounderOf']\n",
    "\n",
    "system_prompt = PromptTemplate(\n",
    "    template = \"\"\"\n",
    "    You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "    Your task is to identify the entities and relations requested with the user prompt, from a given text.\n",
    "    You must generate the output in a JSON containing a list with JSON objects having the following keys: \"head\", \"head_type\", \"relation\", \"tail\", and \"tail_type\".\n",
    "    The \"head\" key must contain the text of the extracted entity with one of the types from the provided list in the user prompt. \n",
    "    The \"head_type\" key must contain the type of the extracted head entity which must be one of the types from {entity_types}.\n",
    "    The \"relation\" key must contain the type of relation between the \"head\" and the \"tail\" which must be one of the relations from {relation_types}.\n",
    "    The \"tail\" key must represent the text of an extracted entity which is the tail of the relation, and the \"tail_type\" key must contain the type of the tail entity from {entity_types}. \n",
    "    Attempt to extract as many entities and relations as you can. \n",
    "    \n",
    "    IMPORTANT NOTES:\n",
    "    - Don't add any explanation and text. \n",
    "    \"\"\",\n",
    "    input_variables=[\"entity_types\",\"relation_types\"],\n",
    ")\n",
    "\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt = system_prompt)\n",
    "\n",
    "examples = [\n",
    "        {\n",
    "            \"text\":\"Adam is a software engineer in Microsoft since 2009, and last year he got an award as the Best Talent\" ,    \n",
    "            \"head\": \"Adam\",\n",
    "            \"head_type\": \"person\",\n",
    "            \"relation\": \"worksFor\",\n",
    "            \"tail\": \"Microsoft\",\n",
    "            \"tail_type\": \"company\"\n",
    "        },\n",
    "        {\n",
    "            \"text\":\"Adam is a software engineer in Microsoft since 2009, and last year he got an award as the Best Talent\" ,    \n",
    "            \"head\": \"Adam\",\n",
    "            \"head_type\": \"person\",\n",
    "            \"relation\": \"hasAward\",\n",
    "            \"tail\": \"Best Talent\",\n",
    "            \"tail_type\": \"award\"\n",
    "        },\n",
    "        {\n",
    "            \"text\":\"Microsoft is a tech company that provide several products such as Microsoft Word\" ,    \n",
    "            \"head\": \"Microsoft Word\",\n",
    "            \"head_type\": \"product\",\n",
    "            \"relation\": \"isproducedBy\",\n",
    "            \"tail\": \"Microsoft\",\n",
    "            \"tail_type\": \"company\"\n",
    "        },\n",
    "        {\n",
    "            \"text\":\"Microsoft Word is a lightweight app that accessible offline\" ,    \n",
    "            \"head\": \"Microsoft Word\",\n",
    "            \"head_type\": \"product\",\n",
    "            \"relation\": \"hasCharacteristic\",\n",
    "            \"tail\": \"lightweight app\",\n",
    "            \"tail_type\": \"characteristic\"\n",
    "        },\n",
    "        {\n",
    "            \"text\":\"Microsoft Word is a lightweight app that accessible offline\" ,    \n",
    "            \"head\": \"Microsoft Word\",\n",
    "            \"head_type\": \"product\",\n",
    "            \"relation\": \"hasCharacteristic\",\n",
    "            \"tail\": \"accesible offline\",\n",
    "            \"tail_type\": \"characteristic\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "class ExtractedInfo(BaseModel):\n",
    "    head: str = Field(description=\"extracted first or head entity like Microsoft, Apple, John\")\n",
    "    head_type: str = Field(description=\"type of the extracted head entity like person, company, etc\")\n",
    "    relation: str = Field(description=\"relation between the head and the tail entities\")\n",
    "    tail: str = Field(description=\"extracted second or tail entity like Microsoft, Apple, John\")\n",
    "    tail_type: str = Field(description=\"type of the extracted tail entity like person, company, etc\")\n",
    "    \n",
    "parser = JsonOutputParser(pydantic_object=ExtractedInfo)\n",
    "\n",
    "human_prompt = PromptTemplate(\n",
    "    template = \"\"\" Based on the following example, extract entities and relations from the provided text.\\n\\n\n",
    "\n",
    "    Use the following entity types, don't use other entity that is not defined below:\n",
    "    # ENTITY TYPES:\n",
    "    {entity_types}\n",
    "\n",
    "    Use the following relation types, don't use other relation that is not defined below:\n",
    "    # RELATION TYPES:\n",
    "    {relation_types}\n",
    "\n",
    "    Below are a number of examples of text and their extracted entities and relationshhips.\n",
    "    {examples}\n",
    "\n",
    "    For the following text, generate extract entitites and relations as in the provided example.\\n{format_instructions}\\nText: {text}\"\"\",\n",
    "    input_variables=[\"entity_types\",\"relation_types\",\"examples\",\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# model = ChatOllama(model = \"mistral\",temperature=0)\n",
    "# model = ChatOllama(model = \"llama3\",temperature=0)\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "chain = LLMChain(llm=model, prompt=chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"head\": {\"title\": \"Head\", \"description\": \"extracted first or head entity like Microsoft, Apple, John\", \"type\": \"string\"}, \"head_type\": {\"title\": \"Head Type\", \"description\": \"type of the extracted head entity like person, company, etc\", \"type\": \"string\"}, \"relation\": {\"title\": \"Relation\", \"description\": \"relation between the head and the tail entities\", \"type\": \"string\"}, \"tail\": {\"title\": \"Tail\", \"description\": \"extracted second or tail entity like Microsoft, Apple, John\", \"type\": \"string\"}, \"tail_type\": {\"title\": \"Tail Type\", \"description\": \"type of the extracted tail entity like person, company, etc\", \"type\": \"string\"}}, \"required\": [\"head\", \"head_type\", \"relation\", \"tail\", \"tail_type\"]}\\n```'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"worksFor\",\n",
      "        \"tail\": \"Apple Inc.\",\n",
      "        \"tail_type\": \"company\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Steve Jobs\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"isFounderOf\",\n",
      "        \"tail\": \"Apple Inc.\",\n",
      "        \"tail_type\": \"company\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Scott Forstall\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"worksFor\",\n",
      "        \"tail\": \"Apple Inc.\",\n",
      "        \"tail_type\": \"company\"\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"isFounderOf\",\n",
      "        \"tail\": \"Apple\",\n",
      "        \"tail_type\": \"company\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"worksFor\",\n",
      "        \"tail\": \"Apple\",\n",
      "        \"tail_type\": \"company\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"hasAward\",\n",
      "        \"tail\": \"Canadian military historian\",\n",
      "        \"tail_type\": \"award\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"hasCharacteristic\",\n",
      "        \"tail\": \"leadership\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"hasCharacteristic\",\n",
      "        \"tail\": \"background in operations\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"hasCharacteristic\",\n",
      "        \"tail\": \"accolades\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Tim Cook\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"hasProject\",\n",
      "        \"tail\": \"diversity and treatment of women in the workplace\",\n",
      "        \"tail_type\": \"project\"\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Steve Jobs\",\n",
      "        \"head_type\": \"person\",\n",
      "        \"relation\": \"isFounderOf\",\n",
      "        \"tail\": \"Apple\",\n",
      "        \"tail_type\": \"company\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasProject\",\n",
      "        \"tail\": \"development of iconic devices\",\n",
      "        \"tail_type\": \"project\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasProject\",\n",
      "        \"tail\": \"transition to new processors\",\n",
      "        \"tail_type\": \"project\"\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Apple Maps\",\n",
      "        \"head_type\": \"product\",\n",
      "        \"relation\": \"isProducedBy\",\n",
      "        \"tail\": \"Apple\",\n",
      "        \"tail_type\": \"company\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple Maps\",\n",
      "        \"head_type\": \"product\",\n",
      "        \"relation\": \"acquired\",\n",
      "        \"tail\": \"technological advancements\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple Maps\",\n",
      "        \"head_type\": \"product\",\n",
      "        \"relation\": \"acquired\",\n",
      "        \"tail\": \"mapping services\",\n",
      "        \"tail_type\": \"product\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasProject\",\n",
      "        \"tail\": \"Apple Maps\",\n",
      "        \"tail_type\": \"product\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasProject\",\n",
      "        \"tail\": \"improve mapping services\",\n",
      "        \"tail_type\": \"product\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasProject\",\n",
      "        \"tail\": \"technological advancements\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"head\": \"Apple Inc.\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasCharacteristic\",\n",
      "        \"tail\": \"technological advancements\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    },\n",
      "    {\n",
      "        \"head\": \"Apple Inc.\",\n",
      "        \"head_type\": \"company\",\n",
      "        \"relation\": \"hasCharacteristic\",\n",
      "        \"tail\": \"ongoing efforts to enhance user experience and innovation\",\n",
      "        \"tail_type\": \"characteristic\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./clean_data/clean_summary.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read the entire file contents into a string\n",
    "    file_contents = file.read()\n",
    "\n",
    "# Split the file contents into sentences\n",
    "sentences = file_contents.split('. ')\n",
    "\n",
    "result = []\n",
    "# Iterate over each sentence\n",
    "for sentence in sentences:\n",
    "    # Process each sentence\n",
    "    response = chain.run(entity_types = entity_types, relation_types = relation_types, examples = examples, text = sentence)\n",
    "    print(response)\n",
    "    try:\n",
    "        result.extend(eval(response))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean_data/clean_result.txt\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Cypher Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'head': 'Tim Cook', 'head_type': 'person', 'relation': 'worksFor', 'tail': 'Apple Inc.', 'tail_type': 'company'}, {'head': 'Steve Jobs', 'head_type': 'person', 'relation': 'isFounderOf', 'tail': 'Apple Inc.', 'tail_type': 'company'}, {'head': 'Scott Forstall', 'head_type': 'person', 'relation': 'worksFor', 'tail': 'Apple Inc.', 'tail_type': 'company'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'isFounderOf', 'tail': 'Apple', 'tail_type': 'company'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'worksFor', 'tail': 'Apple', 'tail_type': 'company'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'hasAward', 'tail': 'Canadian military historian', 'tail_type': 'award'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'hasCharacteristic', 'tail': 'leadership', 'tail_type': 'characteristic'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'hasCharacteristic', 'tail': 'background in operations', 'tail_type': 'characteristic'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'hasCharacteristic', 'tail': 'accolades', 'tail_type': 'characteristic'}, {'head': 'Tim Cook', 'head_type': 'person', 'relation': 'hasProject', 'tail': 'diversity and treatment of women in the workplace', 'tail_type': 'project'}, {'head': 'Steve Jobs', 'head_type': 'person', 'relation': 'isFounderOf', 'tail': 'Apple', 'tail_type': 'company'}, {'head': 'Apple', 'head_type': 'company', 'relation': 'hasProject', 'tail': 'development of iconic devices', 'tail_type': 'project'}, {'head': 'Apple', 'head_type': 'company', 'relation': 'hasProject', 'tail': 'transition to new processors', 'tail_type': 'project'}, {'head': 'Apple Maps', 'head_type': 'product', 'relation': 'isProducedBy', 'tail': 'Apple', 'tail_type': 'company'}, {'head': 'Apple Maps', 'head_type': 'product', 'relation': 'acquired', 'tail': 'technological advancements', 'tail_type': 'characteristic'}, {'head': 'Apple Maps', 'head_type': 'product', 'relation': 'acquired', 'tail': 'mapping services', 'tail_type': 'product'}, {'head': 'Apple', 'head_type': 'company', 'relation': 'hasProject', 'tail': 'Apple Maps', 'tail_type': 'product'}, {'head': 'Apple', 'head_type': 'company', 'relation': 'hasProject', 'tail': 'improve mapping services', 'tail_type': 'product'}, {'head': 'Apple', 'head_type': 'company', 'relation': 'hasProject', 'tail': 'technological advancements', 'tail_type': 'characteristic'}, {'head': 'Apple Inc.', 'head_type': 'company', 'relation': 'hasCharacteristic', 'tail': 'technological advancements', 'tail_type': 'characteristic'}, {'head': 'Apple Inc.', 'head_type': 'company', 'relation': 'hasCharacteristic', 'tail': 'ongoing efforts to enhance user experience and innovation', 'tail_type': 'characteristic'}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./clean_data/clean_result.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "entity_relations = eval(content)\n",
    "print(entity_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>head_type</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>tail_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>worksFor</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steve Jobs</td>\n",
       "      <td>person</td>\n",
       "      <td>isFounderOf</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scott Forstall</td>\n",
       "      <td>person</td>\n",
       "      <td>worksFor</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>isFounderOf</td>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>worksFor</td>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>hasAward</td>\n",
       "      <td>Canadian military historian</td>\n",
       "      <td>award</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>hasCharacteristic</td>\n",
       "      <td>leadership</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>hasCharacteristic</td>\n",
       "      <td>background in operations</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>hasCharacteristic</td>\n",
       "      <td>accolades</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tim Cook</td>\n",
       "      <td>person</td>\n",
       "      <td>hasProject</td>\n",
       "      <td>diversity and treatment of women in the workplace</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Jobs</td>\n",
       "      <td>person</td>\n",
       "      <td>isFounderOf</td>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "      <td>hasProject</td>\n",
       "      <td>development of iconic devices</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "      <td>hasProject</td>\n",
       "      <td>transition to new processors</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Apple Maps</td>\n",
       "      <td>product</td>\n",
       "      <td>isProducedBy</td>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Apple Maps</td>\n",
       "      <td>product</td>\n",
       "      <td>acquired</td>\n",
       "      <td>technological advancements</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Apple Maps</td>\n",
       "      <td>product</td>\n",
       "      <td>acquired</td>\n",
       "      <td>mapping services</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "      <td>hasProject</td>\n",
       "      <td>Apple Maps</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "      <td>hasProject</td>\n",
       "      <td>improve mapping services</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "      <td>hasProject</td>\n",
       "      <td>technological advancements</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>company</td>\n",
       "      <td>hasCharacteristic</td>\n",
       "      <td>technological advancements</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>company</td>\n",
       "      <td>hasCharacteristic</td>\n",
       "      <td>ongoing efforts to enhance user experience and...</td>\n",
       "      <td>characteristic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              head head_type           relation  \\\n",
       "0         Tim Cook    person           worksFor   \n",
       "1       Steve Jobs    person        isFounderOf   \n",
       "2   Scott Forstall    person           worksFor   \n",
       "3         Tim Cook    person        isFounderOf   \n",
       "4         Tim Cook    person           worksFor   \n",
       "5         Tim Cook    person           hasAward   \n",
       "6         Tim Cook    person  hasCharacteristic   \n",
       "7         Tim Cook    person  hasCharacteristic   \n",
       "8         Tim Cook    person  hasCharacteristic   \n",
       "9         Tim Cook    person         hasProject   \n",
       "10      Steve Jobs    person        isFounderOf   \n",
       "11           Apple   company         hasProject   \n",
       "12           Apple   company         hasProject   \n",
       "13      Apple Maps   product       isProducedBy   \n",
       "14      Apple Maps   product           acquired   \n",
       "15      Apple Maps   product           acquired   \n",
       "16           Apple   company         hasProject   \n",
       "17           Apple   company         hasProject   \n",
       "18           Apple   company         hasProject   \n",
       "19      Apple Inc.   company  hasCharacteristic   \n",
       "20      Apple Inc.   company  hasCharacteristic   \n",
       "\n",
       "                                                 tail       tail_type  \n",
       "0                                          Apple Inc.         company  \n",
       "1                                          Apple Inc.         company  \n",
       "2                                          Apple Inc.         company  \n",
       "3                                               Apple         company  \n",
       "4                                               Apple         company  \n",
       "5                         Canadian military historian           award  \n",
       "6                                          leadership  characteristic  \n",
       "7                            background in operations  characteristic  \n",
       "8                                           accolades  characteristic  \n",
       "9   diversity and treatment of women in the workplace         project  \n",
       "10                                              Apple         company  \n",
       "11                      development of iconic devices         project  \n",
       "12                       transition to new processors         project  \n",
       "13                                              Apple         company  \n",
       "14                         technological advancements  characteristic  \n",
       "15                                   mapping services         product  \n",
       "16                                         Apple Maps         product  \n",
       "17                           improve mapping services         product  \n",
       "18                         technological advancements  characteristic  \n",
       "19                         technological advancements  characteristic  \n",
       "20  ongoing efforts to enhance user experience and...  characteristic  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(entity_relations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Steve Jobs', 'person'), ('background in operations', 'characteristic'), ('transition to new processors', 'project'), ('Tim Cook', 'person'), ('leadership', 'characteristic'), ('Apple Inc.', 'company'), ('Apple Maps', 'product'), ('diversity and treatment of women in the workplace', 'project'), ('mapping services', 'product'), ('ongoing efforts to enhance user experience and innovation', 'characteristic'), ('Canadian military historian', 'award'), ('accolades', 'characteristic'), ('development of iconic devices', 'project'), ('Apple', 'company'), ('technological advancements', 'characteristic'), ('improve mapping services', 'product'), ('Scott Forstall', 'person')]\n"
     ]
    }
   ],
   "source": [
    "unique_entities = set()\n",
    "for item in entity_relations:\n",
    "    unique_entities.add((item['head'], item['head_type']))\n",
    "    unique_entities.add((item['tail'], item['tail_type']))\n",
    "\n",
    "unique_entities_list = list(unique_entities)\n",
    "print(unique_entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cypher_query.txt\", \"a\") as file:\n",
    "    for item in unique_entities_list:\n",
    "        label, entity = item\n",
    "        id = label.replace(\" \",\"_\").replace(\"-\",\"\").replace(\"'\",\"\").lower()\n",
    "        merge_statement = f\"\"\"MERGE ({id}:{entity} {{id: \"{label}\"}})\\n\"\"\"\n",
    "        file.write(merge_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cypher_query.txt\", \"a\") as file:\n",
    "    for item in entity_relations:\n",
    "        head = item['head'].replace(\" \",\"_\").replace(\"-\",\"\").replace(\"'\",\"\").lower()\n",
    "        tail = item['tail'].replace(\" \",\"_\").replace(\"-\",\"\").replace(\"'\",\"\").lower()\n",
    "        cypher = f\"\"\"MERGE ({head})-[:{item['relation']}]->({tail})\\n\"\"\"\n",
    "        file.write(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URL = \"neo4j://localhost:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"fireinthehole\"\n",
    "NEO4J_DATABASE = 'neo4j'\n",
    "\n",
    "graph = Neo4jGraph(url=NEO4J_URL, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete everything in a database\n",
    "cypher = \"\"\"\n",
    "MATCH (n)\n",
    "DETACH DELETE n\n",
    "\"\"\"\n",
    "graph.query(cypher)\n",
    "\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Generated Cypher Statement is not valid\n{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '.': expected a graph pattern, a parameter, ')', ':', 'IS', 'WHERE' or '{' (line 6, column 17 (offset: 318))\n\"MERGE (apple_inc.:company {id: \"Apple Inc.\"})\"\n                 ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_community/graphs/neo4j_graph.py:419\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/work/session.py:314\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpersonated_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_access_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbookmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_min_severity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotifications_disabled_classifications\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/work/result.py:221\u001b[0m, in \u001b[0;36mResult._run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/work/result.py:409\u001b[0m, in \u001b[0;36mResult._attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:178\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py:860\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    857\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    858\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[1;32m    859\u001b[0m )\n\u001b[0;32m--> 860\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/io/_bolt5.py:370\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/neo4j/_sync/io/_common.py:245\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    244\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[0;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '.': expected a graph pattern, a parameter, ')', ':', 'IS', 'WHERE' or '{' (line 6, column 17 (offset: 318))\n\"MERGE (apple_inc.:company {id: \"Apple Inc.\"})\"\n                 ^}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcypher_query.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     queries \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.9/site-packages/langchain_community/graphs/neo4j_graph.py:425\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[0;34m(self, query, params)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_data\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CypherSyntaxError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Cypher Statement is not valid\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Generated Cypher Statement is not valid\n{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '.': expected a graph pattern, a parameter, ')', ':', 'IS', 'WHERE' or '{' (line 6, column 17 (offset: 318))\n\"MERGE (apple_inc.:company {id: \"Apple Inc.\"})\"\n                 ^}"
     ]
    }
   ],
   "source": [
    "with open(\"cypher_query.txt\", \"r\") as file:\n",
    "    queries = file.read()\n",
    "graph.query(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace string to fix\n",
    "# Remove dot character\n",
    "!sed -i 's/apple_inc./apple_inc/g' cypher_query.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"cypher_query.txt\", \"r\") as file:\n",
    "    queries = file.read()\n",
    "graph.query(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "person {id: STRING}\n",
      "characteristic {id: STRING}\n",
      "project {id: STRING}\n",
      "company {id: STRING}\n",
      "product {id: STRING}\n",
      "award {id: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:person)-[:isFounderOf]->(:company)\n",
      "(:person)-[:hasProject]->(:project)\n",
      "(:person)-[:hasCharacteristic]->(:characteristic)\n",
      "(:person)-[:worksFor]->(:company)\n",
      "(:person)-[:hasAward]->(:award)\n",
      "(:company)-[:hasCharacteristic]->(:characteristic)\n",
      "(:company)-[:hasProject]->(:characteristic)\n",
      "(:company)-[:hasProject]->(:product)\n",
      "(:company)-[:hasProject]->(:project)\n",
      "(:product)-[:isProducedBy]->(:company)\n",
      "(:product)-[:acquired]->(:product)\n",
      "(:product)-[:acquired]->(:characteristic)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
